{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from IPython.display import display, HTML, JSON, Markdown\n",
    "\n",
    "# Configure environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openailabs303474.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
    "OPENAI_MODEL_NAME = os.getenv(\"OPENAI_MODEL_NAME\")\n",
    "OPENAI_DEPLOYMENT_VERSION = os.getenv(\"OPENAI_DEPLOYMENT_VERSION\")\n",
    "\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\n",
    "    \"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_MODEL_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_MODEL_NAME\")\n",
    "\n",
    "# Configure OpenAI API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OPENAI_DEPLOYMENT_VERSION\n",
    "openai.api_base = OPENAI_DEPLOYMENT_ENDPOINT\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "# ---\n",
    "credential = AzureKeyCredential(key)\n",
    "\n",
    "print(OPENAI_DEPLOYMENT_ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_llm(model=OPENAI_MODEL_NAME,\n",
    "             deployment_name=OPENAI_DEPLOYMENT_NAME,\n",
    "             temperature=0,\n",
    "             max_tokens=500,\n",
    "             ):\n",
    "\n",
    "    llm = AzureOpenAI(deployment_name=deployment_name,\n",
    "                      model=model,\n",
    "                      temperature=temperature,\n",
    "                      max_tokens=max_tokens,\n",
    "                      model_kwargs={\"stop\": [\"<|im_end|>\"]}\n",
    "                      )\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Document Embeddings using OpenAI Ada 002\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(page):\n",
    "    response = openai.Embedding.create(\n",
    "        input=page, engine=\"text-embedding-ada-002\")\n",
    "\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" System:\n",
    "You are assistant helping the company technical support users with their questions about different product features. \n",
    "Answer ONLY with the facts listed in the sources below delimited by triple backticks.\n",
    "If there isn't enough information in the Sources, say you don't know and ask a user to provide more details. \n",
    "Do not generate answers that don't use the Sources below. \n",
    "If asking a clarifying question to the user would help, ask the question. \n",
    "\n",
    "Sources:\n",
    "```{sources}```\n",
    "User question is here below delimited by triple backticks\n",
    "User:\n",
    "```{question}``` \n",
    "\n",
    "You answer is here below:\n",
    "Answer:\n",
    "<|im_end|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = init_llm()\n",
    "# ConversationBufferMemory is a memory that stores the conversation history\n",
    "memory = ConversationBufferMemory()\n",
    "# try to change the verbose to True, to see more details\n",
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_client = SearchClient(\n",
    "\n",
    "    service_endpoint, index_name=\"sk-cogsrch-vector-index-2\", credential=credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search(question, top_k=3):\n",
    "    results = search_client.search(\n",
    "        search_text=None,\n",
    "        vector=generate_embeddings(question),\n",
    "        top_k=top_k,\n",
    "        vector_fields=\"contentVector\",\n",
    "        select=[\"title\", \"content\"],\n",
    "    )\n",
    "\n",
    "    result_pages = []\n",
    "    for result in results:\n",
    "        result_pages.append(result['content'])\n",
    "\n",
    "    sources = \"\\n\\n\".join([page for page in result_pages])\n",
    "    return sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_openai(sources, question):\n",
    "    prompt = ChatPromptTemplate.from_template(template=template)\n",
    "    response = conversation.run(input=prompt.format(sources=sources,\n",
    "                                                    question=question))\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Semantic Kernel is an open-source SDK that lets you easily combine AI services like OpenAI, Azure OpenAI, and Hugging Face with conventional programming languages like C# and Python. By doing so, you can create AI apps that combine the best of both worlds. During Kevin Scott's talk The era of the AI Copilot, he showed how Microsoft powers its Copilot system with a stack of AI models and plugins. At the center of this stack is an AI orchestration layer that allows us to combine AI models and plugins together to create brand new experiences for users. Semantic Kernel is at the center of the copilot stack."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"what's semnatic kernel\"\n",
    "sources = search(question, top_k=3)  # retrieval\n",
    "#print(sources)\n",
    "# generation - second part of RAG\n",
    "response = ask_openai(sources, question)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported Semantic Kernel languages\n",
      "Article ‚Ä¢07/18/2023\n",
      "Semantic K ernel plans on providing support to the following languages:\n",
      "While the overall architecture of the kernel is consistent across all languages, we made\n",
      "sure the SDK for each language follows common paradigms and styles in each language\n",
      "to make it feel native and easy to use.\n",
      "Today, not all features are available in all languages. The following tables show which\n",
      "features are available in each language. The üîÑ  symbol indicates that the feature is\n",
      "partially implemented, please see the associated note column for more details. The ‚ùå\n",
      "symbol indicates that the feature is not yet available in that language; if you would like\n",
      "to see a feature implemented in a language, please consider contributing to the project\n",
      "or opening an issue .\n",
      "Services C# Python JavaNotes\n",
      "TextGeneration ‚úÖ‚úÖ‚úÖ Example: T ext-Davinci-003\n",
      "TextEmbeddings ‚úÖ‚úÖ‚úÖ Example: T ext-Embeddings-Ada-002\n",
      "ChatCompletion ‚úÖ‚úÖ‚úÖ Example: GPT4, Chat-GPTÔºó Note\n",
      "Skills are currently being renamed to plugins. This article has been updated to\n",
      "reflect the latest terminology, but some images and code samples may still refer to\n",
      "skills.\n",
      "C#ÔºÇ\n",
      "PythonÔºÇ\n",
      "Java ( available here ) ÔºÇ\n",
      "Available features\n",
      "AI Services\n",
      "\n",
      "Semantic Kernel FAQ's\n",
      "Article ‚Ä¢05/23/2023\n",
      "Both C# and Python are popular coding language and we're actively adding additional\n",
      "languages based on community feedback. Both Java  and Typescript  are on our\n",
      "roadmap and being actively developed in experimental branches.\n",
      "We have sample apps  and plugins you can try out so you can quickly learn the concepts\n",
      "of Semantic K ernel.\n",
      "There are a variety of support options available !\n",
      "Depending upon the model you are trying to access, there may be times when your key\n",
      "may not work because of high demand. Or, because your access to the model is limited\n",
      "by the plan you're currently signed up for ‚Äî so-called \"throttling\". In general, however,\n",
      "your key will work according to the plan agreement with your LLM AI provider.\n",
      "First of all, you'll need to be running locally on your own machine to interact with the\n",
      "Jupyter notebooks. If you've already cleared that hurdle, then all you need to do is to\n",
      "install the Polyglot Extension  which requires .NET 7 to be installed. For complete\n",
      "information on the latest release of P olyglot Extension you can learn more here .Why is the Kernel only in C# and Python?\n",
      "Where are the sample plugins?\n",
      "How do I get help or provide feedback?\n",
      "Is something up with my OpenAI or Azure\n",
      "OpenAI key?\n",
      "Why aren't my Jupyter notebooks coming up in\n",
      "my VSCode or Visual Studio?\n",
      "\n",
      "Visual Code Studio Semantic Kernel\n",
      "Extension\n",
      "Article ‚Ä¢05/23/2023\n",
      "The Semantic K ernel T ools help developers to write semantic functions for Semantic\n",
      "Kernel .\n",
      "With the Semantic K ernel T ools, you can easily create new semantic functions and test\n",
      "them without needing to write any code. Behind the scenes, the tools use the Semantic\n",
      "Kernel SDK so you can easily transition from using the tools to integrating your semantic\n",
      "functions into your own code.\n",
      "In the following image you can see how a user can easily view all of their semantic\n",
      "functions, edit them, and run them from within Visual S tudio Code using any of the\n",
      "supported AI endpoints.\n",
      "Ôºó Note\n",
      "Skills are currently being renamed to plugins. This article has been updated to\n",
      "reflect the latest terminology, but some images and code samples may still refer to\n",
      "skills.\n",
      "These tools simplify Semantic Kernel\n",
      "development\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "  Semantic Kernel plans on providing support to the following languages: C#, Python, Java. While the overall architecture of the kernel is consistent across all languages, the SDK for each language follows common paradigms and styles in each language to make it feel native and easy to use. Today, not all features are available in all languages. The following tables show which features are available in each language. The üîÑ symbol indicates that the feature is partially implemented, please see the associated note column for more details. The ‚ùå symbol indicates that the feature is not yet available in that language; if you would like to see a feature implemented in a language, please consider contributing to the project or opening an issue."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"which programming languages are supported by semantic kernel?\"\n",
    "sources = search(question, top_k=3)\n",
    "#print(sources)\n",
    "response = ask_openai(sources, question)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional learning for Semantic Kernel\n",
      "Article ‚Ä¢07/11/2023\n",
      "Want to learn more about Semantic K ernel? Check out these in-depth tutorials and\n",
      "videos. W e will add more content over time from our team and community, so check\n",
      "back often!\n",
      "Cook with Semantic Kernel\n",
      "Learn how to supercharge your problem-solving creativity with Semantic K ernel running\n",
      "on your own machine just like your own ‚ÄúEasy Bake Oven.‚Äù W e‚Äôll use plenty of cooking\n",
      "analogies to land the core ideas of LLM AI running on Semantic K ernel so be prepared\n",
      "to get hungry!\n",
      "¬†\n",
      "Kernel syntax examplesStart the tut orial\n",
      "\n",
      "Responsible AI and Semantic Kernel\n",
      "Article ‚Ä¢05/23/2023\n",
      "An AI system includes not only the technology, but also the people who will use it, the\n",
      "people who will be affected by it, and the environment in which it is deployed. Creating\n",
      "a system that is fit for its intended purpose requires an understanding of how the\n",
      "technology works, what its capabilities and limitations are, and how to achieve the best\n",
      "performance. Microsoft‚Äôs T ransparency Notes are intended to help you understand how\n",
      "our AI technology works, the choices system owners can make that influence system\n",
      "performance and behavior, and the importance of thinking about the whole system,\n",
      "including the technology, the people, and the environment. Y ou can use T ransparency\n",
      "Notes when developing or deploying your own system, or share them with the people\n",
      "who will use or be affected by your system.\n",
      "Microsoft‚Äôs T ransparency Notes are part of a broader effort at Microsoft to put our AI\n",
      "Principles into practice. T o find out more, see the Microsoft AI principles .\n",
      "Semantic K ernel (SK) is a lightweight SDK that lets you easily mix conventional\n",
      "programming languages with the latest in Large Language Model (LLM) AI \"prompts\"\n",
      "with templating, chaining, and planning capabilities out-of-the-box.\n",
      "Semantic K ernel (SK) builds upon the following five concepts:\n",
      "Concept Shor t Descr iption\n",
      "Kernel The kernel orchestrates a user's ASK expressed as a goal\n",
      "Planner Planner breaks it down into steps based upon resources that are available\n",
      "Plugins Plugins are customizable resources built from LLM AI prompts and native codeWhat is a Transparency Note?\n",
      "Introduction to Semantic Kernel\n",
      "The basics of Semantic Kernel\n",
      "\n",
      "To simplify the creation of AI apps, open source projects like LangChain  have\n",
      "emerged. Semantic K ernel is Microsoft's contribution to this space and is designed to\n",
      "support enterprise app developers who want to integrate AI into their existing apps.\n",
      "By using multiple AI models, plugins, and memory all together within Semantic K ernel,\n",
      "you can create sophisticated pipelines that allow AI to automate complex tasks for users.\n",
      "For example, with Semantic K ernel, you could create a pipeline that helps a user send an\n",
      "email to their marketing team. With memory , you could retrieve information about the\n",
      "project and then use planner  to autogenerate the remaining steps using available\n",
      "plugins (e.g., ground the user's ask with Microsoft Graph data, generate a response with\n",
      "GPT-4, and send the email). Finally, you can display a success message back to your user\n",
      "in your app using a custom plugin.\n",
      "Step Component Descr iption\n",
      "1 Ask It starts with a goal being sent to Semantic K ernel by either a user or\n",
      "developer.\n",
      "2 Kernel The kernel  orchestrates a user's ask. T o do so, the kernel runs a pipeline /\n",
      "chain  that is defined by a developer. While the chain is run, a common\n",
      "context is provided by the kernel so data can be shared between functions.\n",
      "2.1 Memories With a specialized plugin, a developer can recall and store context in\n",
      "vector databases. This allows developers to simulate memory  within their\n",
      "AI apps.\n",
      "2.2 Planner Developers can ask Semantic K ernel to auto create chains to address novel\n",
      "needs for a user. Planner  achieves this by mixing-and-matching plugins\n",
      "Seeing AI orchestration with Semantic Kernel\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "   Semantic Kernel es un SDK de c√≥digo abierto que permite combinar f√°cilmente servicios de inteligencia artificial como OpenAI, Azure OpenAI y Hugging Face con lenguajes de programaci√≥n convencionales como C# y Python. El kernel orquesta el ASK de un usuario expresado como un objetivo. El planificador descompone el objetivo en pasos basados en los recursos disponibles. Los plugins son recursos personalizables construidos a partir de LLM AI prompts y c√≥digo nativo."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"¬øQu√© son el planificador sem√°ntico del kernel y el kernel?\"\n",
    "sources = search(question, top_k=3)\n",
    "print(sources)\n",
    "response = ask_openai(sources, question)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After working locally, i.e. you cloned the code from the GitHub repo  and have made\n",
      "changes to the code for your needs, you can deploy your changes to Azure as a web\n",
      "application.\n",
      "You can use the standard methods available to deploy an ASP.net web app  in order to\n",
      "do so.\n",
      "Alternatively, you can follow the steps below to manually build and upload your\n",
      "customized version of the Semantic K ernel service to Azure.\n",
      "First, at the command line, go to the '/webapi' directory and enter the following\n",
      "command:\n",
      "PowerShell\n",
      "This will create a directory which contains all the files needed for a deployment:\n",
      "Windows Command Prompt\n",
      "Zip the contents of that directory and store the resulting zip file on cloud storage, e.g.\n",
      "Azure Blob Container. Put its URI in the \"P ackage Uri\" field in the web deployment page\n",
      "you access through the \"Deploy to Azure\" buttons or use its URI as the value for the\n",
      "PackageUri parameter of the deployment scripts found on this page .\n",
      "Your deployment will then use your customized deployment package. That package will\n",
      "be used to create a new Azure web app, which will be configured to run your\n",
      "customized version of the Semantic K ernel service.\n",
      "This method is useful for making changes when adding new semantic skills only.\n",
      "1. Go to https://Y OUR_APP_NAME.scm.azurewebsites.net , replacing\n",
      "YOUR_APP_NAME in the URL with your app name found in Azure P ortal. This will\n",
      "dotnet publish CopilotChatApi.csproj  --configuration  Release  --arch x64 --os \n",
      "win\n",
      "../webapi/bin/Release/net6. 0/win-x64/publish'\n",
      "2. Publish skills directly to the Semantic Kernel web app\n",
      "service\n",
      "How to add Semantic Skills\n",
      "\n",
      "Deploy Chat Copilot to Azure as a web\n",
      "app service\n",
      "Article ‚Ä¢08/02/2023\n",
      "In this how-to guide we will provide steps to deploy Semantic K ernel to Azure as a web\n",
      "app service. Deploying Semantic K ernel as web service to Azure provides a great\n",
      "pathway for developers to take advantage of Azure compute and other services such as\n",
      "Azure Cognitive Services for responsible AI and vectorized databases.\n",
      "You can use one of the deployment options to deploy based on your use case and\n",
      "preference.\n",
      "1. Azure currently limits the number of Azure OpenAI resources per region per\n",
      "subscription to 3. Azure OpenAI is not available in every region. (R efer to this\n",
      "availability map ) Bearing this in mind, you might want to use the same Azure\n",
      "OpenAI instance for multiple deployments of Semantic K ernel to Azure.\n",
      "2. F1 and D1 App Service SKU's (the Free and Shared ones) are not supported for this\n",
      "deployment.\n",
      "3. Ensure you have sufficient permissions to create resources in the target\n",
      "subscription.\n",
      "4. Using web frontends to access your deployment: make sure to include your\n",
      "frontend's URL as an allowed origin in your deployment's C ORS settings.\n",
      "Otherwise, web browsers will refuse to let JavaScript make calls to your\n",
      "deployment.\n",
      "Use Case Deployment Option\n",
      "Use existing: Azure OpenAI R esources\n",
      "Use this option to use an existing Azure OpenAI instance and connect\n",
      "the Semantic K ernel web API to it. PowerShell File\n",
      "Bash FileConsiderations\n",
      "\n",
      "Learn how to make changes to the\n",
      "Semantic Kernel web app service\n",
      "Article ‚Ä¢08/02/2023\n",
      "This guide provides steps to make changes to the skills of a deployed instance of the\n",
      "Semantic K ernel web app. Currently, changing semantic skills can be done without\n",
      "redeploying the web app service but changes to native skills do require re-deployments.\n",
      "This document will guide you through the process of doing both.\n",
      "1. An instance of the Semantic K ernel web app service deployed in your Azure\n",
      "subscription. Y ou can follow the how-to guide here for details.\n",
      "2. Have your web app's name handy. If you used the deployment templates provided\n",
      "with the Chat Copilot, you can find the web app's name by going to the Azure\n",
      "Portal  and selecting the resource group created for your Semantic K ernel web\n",
      "app service. Y our web app's name is the one of the resource listed that ends with\n",
      "\"skweb\".\n",
      "3. Locally tested skills  or planner  ready to be added to your Semantic K ernel web app\n",
      "service.\n",
      "There are two main ways to deploy changes to the Semantic K ernel web app service. If\n",
      "you have been working locally and are ready to deploy your changes to Azure as a new\n",
      "web app service, you can follow the steps in the first section. If you have already\n",
      "deployed your Semantic K ernel web app service and want to make changes to add\n",
      "Semantic skills, you can follow the steps in the second section.Prerequisites\n",
      "How to publish changes to the Semantic Kernel\n",
      "web app service\n",
      "1.Deploying your Chat Copilot App to Azure as a web\n",
      "application\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "   To deploy Semantic Kernel to Azure as a web app service, you can follow the steps provided in the \"Deploy Chat Copilot to Azure as a web app service\" article. The article provides two deployment options based on your use case and preference. The first option is to use an existing Azure OpenAI instance and connect the Semantic Kernel web API to it. The second option is to deploy Semantic Kernel to Azure as a new web app service. The article provides detailed steps for each option."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "question = \"explain how to deploy Semantic Kernel to Azure as a web app service\"\n",
    "sources = search(question, top_k=3)\n",
    "print(sources)\n",
    "response = ask_openai(sources, question)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
