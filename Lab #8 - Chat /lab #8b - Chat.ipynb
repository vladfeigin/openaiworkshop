{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries  \n",
    "import os  \n",
    "import json  \n",
    "import openai  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient  \n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.llms import AzureOpenAI\n",
    "from dotenv import load_dotenv  \n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from IPython.display import display, HTML, JSON, Markdown\n",
    "\n",
    "# Configure environment variables  \n",
    "load_dotenv() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://openailabs303474.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\") \n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\") \n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\") \n",
    " \n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") \n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
    "OPENAI_MODEL_NAME = os.getenv(\"OPENAI_MODEL_NAME\")\n",
    "OPENAI_DEPLOYMENT_VERSION = os.getenv(\"OPENAI_DEPLOYMENT_VERSION\")\n",
    "\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_MODEL_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_MODEL_NAME\")\n",
    "\n",
    "# Configure OpenAI API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OPENAI_DEPLOYMENT_VERSION\n",
    "openai.api_base = OPENAI_DEPLOYMENT_ENDPOINT\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "#---\n",
    "credential = AzureKeyCredential(key)\n",
    "\n",
    "print (OPENAI_DEPLOYMENT_ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_llm(model=OPENAI_MODEL_NAME,\n",
    "             deployment_name=OPENAI_DEPLOYMENT_NAME, \n",
    "             temperature=0,\n",
    "             max_tokens=500,\n",
    "             ):\n",
    "    \n",
    "    llm = AzureOpenAI(deployment_name=deployment_name,  \n",
    "                  model=model,\n",
    "                  temperature=temperature,\n",
    "                  max_tokens=max_tokens,\n",
    "                  model_kwargs={\"stop\": [\"<|im_end|>\"]}\n",
    "    ) \n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Document Embeddings using OpenAI Ada 002\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "def generate_embeddings(page):\n",
    "    response = openai.Embedding.create(\n",
    "        input=page, engine=\"text-embedding-ada-002\")\n",
    "   \n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? I hope you are doing well. I am very interested in your project. I have read your project description very carefully. I can make the android app for you. I have developed many android apps for More\\n\\nHello, I have gone through your project details . I can build your mobile application as per your requirements.I am an experienced mobile app developer with an experience of 5+ years. I’m pretty confident that I will More\\n\\nHello, I have gone through your project details . I can build your mobile application as per your requirements.I am an experienced mobile app developer with an experience of 5+ years. I’m pretty confident that I will More\\n\\nHello, I have gone through your project details . I can build your mobile application as per your requirements.I am an experienced mobile app developer with an experience of 5+ years. I’m pretty confident that I will More\\n\\nHello, I have gone through your project details . I can build your mobile application as per your requirements.I am an experienced mobile app developer with an experience of 5+ years. I’m pretty confident that I will More\\n\\nHello, I have gone through your project details . I can build your mobile application as per your requirements.I am an experienced mobile app developer with an experience of 5+ years. I’m pretty confident that I will More\\n\\nHello, I have gone through your project details . I can build your mobile application as per your requirements.I am an experienced mobile app developer with an experience of 5+ years. I’m pretty confident that I will More\\n\\nHello, I have gone through your project details . I can build your mobile application as per your requirements.I am an experienced mobile app developer with an experience of 5+ years. I’m pretty confident that I will More\\n\\nHello, I have gone through your project details . I can build your mobile application as per your requirements.I am an experienced mobile app developer with an experience of 5+ years. I’m pretty confident that I will More\\n\\nHello, I have gone through your project details . I can build your mobile application as per your requirements.I am an experienced mobile app developer with an experience of 5+ years. I’m pretty confident that I will More\\n\\nHello, I have gone through your project details . I can build your mobile application as per your requirements.I am an experienced mobile app developer with an experience of 5+ years. I’m pretty confident that I will More\\n\\nHello, I have gone through your'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the model \n",
    "llm = init_llm()\n",
    "llm(\"hello! How are you today\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" System:\n",
    "You are assistant helping the company technical support users with their questions about different product features. \n",
    "Answer ONLY with the facts listed in the sources below delimited by triple backticks.\n",
    "If there isn't enough information in the Sources, say you don't know and ask a user to provide more details. \n",
    "Do not generate answers that don't use the Sources below. \n",
    "If asking a clarifying question to the user would help, ask the question. \n",
    "\n",
    "Sources:\n",
    "```{sources}```\n",
    "User question is here below delimited by triple backticks\n",
    "User:\n",
    "```{question}``` \n",
    "\n",
    "You answer is here below:\n",
    "Answer:\n",
    "<|im_end|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "#ConversationBufferMemory is a memory that stores the conversation history\n",
    "memory = ConversationBufferMemory()\n",
    "#try to change the verbose to True, to see more details\n",
    "conversation = ConversationChain(llm=llm, memory=memory, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_client = SearchClient(service_endpoint, index_name=\"sk-cogsrch-vector-index\", credential=credential)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search(question, top_k=3):\n",
    "    results = search_client.search(  \n",
    "        search_text=None,\n",
    "        vector=generate_embeddings(question),  \n",
    "        top_k=top_k,  \n",
    "        vector_fields=\"contentVector\",\n",
    "        select=[\"title\", \"content\"],\n",
    "    )  \n",
    "    \n",
    "    result_pages = []\n",
    "    for result in results:\n",
    "        result_pages.append(result['content'])      \n",
    "\n",
    "    sources = \"\\n\\n\".join([page for page in result_pages])\n",
    "    return sources    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ask_openai(sources, question):\n",
    "    prompt = ChatPromptTemplate.from_template(template=template)\n",
    "    response = conversation.run (input=prompt.format(sources=sources,\n",
    "                            question=question))\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell us about y our PDF experience.\n",
      "What is Semantic Kernel?\n",
      "Article •07/11/2023\n",
      "Semantic K ernel is an open-source SDK that lets you easily combine AI services like\n",
      "OpenAI , Azure OpenAI , and Hugging F ace  with conventional programming\n",
      "languages like C# and Python. By doing so, you can create AI apps that combine the\n",
      "best of both worlds.\n",
      "During K evin Scott's talk The era of the AI Copilot , he showed how Microsoft powers its\n",
      "Copilot system  with a stack of AI models and plugins. At the center of this stack is an AI\n",
      "orchestration layer that allows us to combine AI models and plugins together to create\n",
      "brand new experiences for users.\n",
      "Semantic Kernel is at the center of the copilot\n",
      "stack\n",
      "\n",
      "Additional learning for Semantic Kernel\n",
      "Article •07/11/2023\n",
      "Want to learn more about Semantic K ernel? Check out these in-depth tutorials and\n",
      "videos. W e will add more content over time from our team and community, so check\n",
      "back often!\n",
      "Cook with Semantic Kernel\n",
      "Learn how to supercharge your problem-solving creativity with Semantic K ernel running\n",
      "on your own machine just like your own “Easy Bake Oven.” W e’ll use plenty of cooking\n",
      "analogies to land the core ideas of LLM AI running on Semantic K ernel so be prepared\n",
      "to get hungry!\n",
      " \n",
      "Kernel syntax examplesStart the tut orial\n",
      "\n",
      "Visual Code Studio Semantic Kernel\n",
      "Extension\n",
      "Article •05/23/2023\n",
      "The Semantic K ernel T ools help developers to write semantic functions for Semantic\n",
      "Kernel .\n",
      "With the Semantic K ernel T ools, you can easily create new semantic functions and test\n",
      "them without needing to write any code. Behind the scenes, the tools use the Semantic\n",
      "Kernel SDK so you can easily transition from using the tools to integrating your semantic\n",
      "functions into your own code.\n",
      "In the following image you can see how a user can easily view all of their semantic\n",
      "functions, edit them, and run them from within Visual S tudio Code using any of the\n",
      "supported AI endpoints.\n",
      "７ Note\n",
      "Skills are currently being renamed to plugins. This article has been updated to\n",
      "reflect the latest terminology, but some images and code samples may still refer to\n",
      "skills.\n",
      "These tools simplify Semantic Kernel\n",
      "development\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "   Semantic Kernel is an open-source SDK that lets you easily combine AI services like OpenAI, Azure OpenAI, and Hugging Face with conventional programming languages like C# and Python. By doing so, you can create AI apps that combine the best of both worlds. During Kevin Scott's talk \"The era of the AI Copilot\", he showed how Microsoft powers its Copilot system with a stack of AI models and plugins. At the center of this stack is an AI orchestration layer that allows us to combine AI models and plugins together to create brand new experiences for users. Semantic Kernel is at the center of the copilot stack."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"what's semnatic kernel?\"\n",
    "sources = search(question, top_k=3)\n",
    "print (sources)\n",
    "response = ask_openai(sources, question)\n",
    "display (Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported Semantic Kernel languages\n",
      "Article •07/18/2023\n",
      "Semantic K ernel plans on providing support to the following languages:\n",
      "While the overall architecture of the kernel is consistent across all languages, we made\n",
      "sure the SDK for each language follows common paradigms and styles in each language\n",
      "to make it feel native and easy to use.\n",
      "Today, not all features are available in all languages. The following tables show which\n",
      "features are available in each language. The 🔄  symbol indicates that the feature is\n",
      "partially implemented, please see the associated note column for more details. The ❌\n",
      "symbol indicates that the feature is not yet available in that language; if you would like\n",
      "to see a feature implemented in a language, please consider contributing to the project\n",
      "or opening an issue .\n",
      "Services C# Python JavaNotes\n",
      "TextGeneration ✅✅✅ Example: T ext-Davinci-003\n",
      "TextEmbeddings ✅✅✅ Example: T ext-Embeddings-Ada-002\n",
      "ChatCompletion ✅✅❌ Example: GPT4, Chat-GPT７ Note\n",
      "Skills are currently being renamed to plugins. This article has been updated to\n",
      "reflect the latest terminology, but some images and code samples may still refer to\n",
      "skills.\n",
      "C#＂\n",
      "Python＂\n",
      "Java ( coming soon ) ＂\n",
      "Available features\n",
      "AI Services\n",
      "\n",
      "Semantic Kernel FAQ's\n",
      "Article •05/23/2023\n",
      "Both C# and Python are popular coding language and we're actively adding additional\n",
      "languages based on community feedback. Both Java  and Typescript  are on our\n",
      "roadmap and being actively developed in experimental branches.\n",
      "We have sample apps  and plugins you can try out so you can quickly learn the concepts\n",
      "of Semantic K ernel.\n",
      "There are a variety of support options available !\n",
      "Depending upon the model you are trying to access, there may be times when your key\n",
      "may not work because of high demand. Or, because your access to the model is limited\n",
      "by the plan you're currently signed up for — so-called \"throttling\". In general, however,\n",
      "your key will work according to the plan agreement with your LLM AI provider.\n",
      "First of all, you'll need to be running locally on your own machine to interact with the\n",
      "Jupyter notebooks. If you've already cleared that hurdle, then all you need to do is to\n",
      "install the Polyglot Extension  which requires .NET 7 to be installed. For complete\n",
      "information on the latest release of P olyglot Extension you can learn more here .Why is the Kernel only in C# and Python?\n",
      "Where are the sample plugins?\n",
      "How do I get help or provide feedback?\n",
      "Is something up with my OpenAI or Azure\n",
      "OpenAI key?\n",
      "Why aren't my Jupyter notebooks coming up in\n",
      "my VSCode or Visual Studio?\n",
      "\n",
      "Visual Code Studio Semantic Kernel\n",
      "Extension\n",
      "Article •05/23/2023\n",
      "The Semantic K ernel T ools help developers to write semantic functions for Semantic\n",
      "Kernel .\n",
      "With the Semantic K ernel T ools, you can easily create new semantic functions and test\n",
      "them without needing to write any code. Behind the scenes, the tools use the Semantic\n",
      "Kernel SDK so you can easily transition from using the tools to integrating your semantic\n",
      "functions into your own code.\n",
      "In the following image you can see how a user can easily view all of their semantic\n",
      "functions, edit them, and run them from within Visual S tudio Code using any of the\n",
      "supported AI endpoints.\n",
      "７ Note\n",
      "Skills are currently being renamed to plugins. This article has been updated to\n",
      "reflect the latest terminology, but some images and code samples may still refer to\n",
      "skills.\n",
      "These tools simplify Semantic Kernel\n",
      "development\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "   Semantic Kernel plans on providing support to the following languages: C#, Python, Java (coming soon). While the overall architecture of the kernel is consistent across all languages, the SDK for each language follows common paradigms and styles in each language to make it feel native and easy to use. Today, not all features are available in all languages. The following tables show which features are available in each language. The 🔄 symbol indicates that the feature is partially implemented, please see the associated note column for more details. The ❌ symbol indicates that the feature is not yet available in that language; if you would like to see a feature implemented in a language, please consider contributing to the project or opening an issue."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"which programming languages are supported by semantic kernel?\"\n",
    "sources = search(question, top_k=3)\n",
    "print (sources)\n",
    "response = ask_openai(sources, question)\n",
    "display (Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn how to deploy Semantic Kernel to\n",
      "Azure as a web app service\n",
      "Article •05/24/2023\n",
      "In this how-to guide we will provide steps to deploy Semantic K ernel to Azure as a web\n",
      "app service. Deploying Semantic K ernel as web service to Azure provides a great\n",
      "pathway for developers to take advantage of Azure compute and other services such as\n",
      "Azure Cognitive Services for responsible AI and vectorized databases.\n",
      "You can use one of the deployment options to deploy based on your use case and\n",
      "preference.\n",
      "1. Azure currently limits the number of Azure OpenAI resources per region per\n",
      "subscription to 3. Azure OpenAI is not available in every region. (R efer to this\n",
      "availability map ) Bearing this in mind, you might want to use the same Azure\n",
      "OpenAI instance for multiple deployments of Semantic K ernel to Azure.\n",
      "2. F1 and D1 App Service SKU's (the Free and Shared ones) are not supported for this\n",
      "deployment.\n",
      "3. Ensure you have sufficient permissions to create resources in the target\n",
      "subscription.\n",
      "4. Using web frontends to access your deployment: make sure to include your\n",
      "frontend's URL as an allowed origin in your deployment's C ORS settings.\n",
      "Otherwise, web browsers will refuse to let JavaScript make calls to your\n",
      "deployment.  \n",
      "Use Case Deployment\n",
      "Option\n",
      "Use existing: Azure OpenAI R esources\n",
      "Use this option to use an existing Azure OpenAI instance and connect the\n",
      "Semantic K ernel web API to it.PowerShell File  \n",
      "Bash FileConsiderations\n",
      "\n",
      "Start learning how to use Semantic\n",
      "Kernel\n",
      "Article •07/11/2023\n",
      "In just a few steps, you can start running the getting started guides for Semantic K ernel\n",
      "in either C# or Python. After completing the guides, you'll know how to...\n",
      "Configure your local machine to run Semantic K ernel\n",
      "Run AI prompts from the kernel\n",
      "Make AI prompts dynamic with variables\n",
      "Create a simple AI chatbot\n",
      "Automatically combine functions together with planner\n",
      "Store and retrieve memory with embeddings\n",
      "If you are an experienced developer, you can skip the guides and directly access the\n",
      "packages from the Nuget feed or PyPI.\n",
      "Instructions for accessing the SemanticKernel Nuget feed is available here . It's as\n",
      "easy as:\n",
      "Nuget\n",
      "Before running the guides in C#, make sure you have the following installed on your\n",
      "local machine.C#\n",
      "#r \"nuget: Microsoft.SemanticKernel, *-*\"\n",
      "Requirements to run the guides\n",
      "git or the GitHub app＂\n",
      "VSCode  or Visual S tudio ＂\n",
      "An OpenAI key via either Azure OpenAI Service  or OpenAI ＂\n",
      ".Net 7 SDK  - for C# notebook guides＂\n",
      "In VS Code the Polyglot Notebook  - for notebook guides ＂\n",
      "\n",
      "Tell us about y our PDF experience.\n",
      "What is Semantic Kernel?\n",
      "Article •07/11/2023\n",
      "Semantic K ernel is an open-source SDK that lets you easily combine AI services like\n",
      "OpenAI , Azure OpenAI , and Hugging F ace  with conventional programming\n",
      "languages like C# and Python. By doing so, you can create AI apps that combine the\n",
      "best of both worlds.\n",
      "During K evin Scott's talk The era of the AI Copilot , he showed how Microsoft powers its\n",
      "Copilot system  with a stack of AI models and plugins. At the center of this stack is an AI\n",
      "orchestration layer that allows us to combine AI models and plugins together to create\n",
      "brand new experiences for users.\n",
      "Semantic Kernel is at the center of the copilot\n",
      "stack\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "   You can use an existing Azure OpenAI instance and connect the Semantic Kernel web API to it. To do so, follow the steps in the \"Use existing: Azure OpenAI Resources\" option in the \"Considerations\" section of the \"Learn how to deploy Semantic Kernel to Azure as a web app service\" source."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Provide steps for using Azure OpenAI model with semantic kernel\"\n",
    "sources = search(question, top_k=3)\n",
    "print (sources)\n",
    "response = ask_openai(sources, question)\n",
    "display (Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn how to deploy Semantic Kernel to\n",
      "Azure as a web app service\n",
      "Article •05/24/2023\n",
      "In this how-to guide we will provide steps to deploy Semantic K ernel to Azure as a web\n",
      "app service. Deploying Semantic K ernel as web service to Azure provides a great\n",
      "pathway for developers to take advantage of Azure compute and other services such as\n",
      "Azure Cognitive Services for responsible AI and vectorized databases.\n",
      "You can use one of the deployment options to deploy based on your use case and\n",
      "preference.\n",
      "1. Azure currently limits the number of Azure OpenAI resources per region per\n",
      "subscription to 3. Azure OpenAI is not available in every region. (R efer to this\n",
      "availability map ) Bearing this in mind, you might want to use the same Azure\n",
      "OpenAI instance for multiple deployments of Semantic K ernel to Azure.\n",
      "2. F1 and D1 App Service SKU's (the Free and Shared ones) are not supported for this\n",
      "deployment.\n",
      "3. Ensure you have sufficient permissions to create resources in the target\n",
      "subscription.\n",
      "4. Using web frontends to access your deployment: make sure to include your\n",
      "frontend's URL as an allowed origin in your deployment's C ORS settings.\n",
      "Otherwise, web browsers will refuse to let JavaScript make calls to your\n",
      "deployment.  \n",
      "Use Case Deployment\n",
      "Option\n",
      "Use existing: Azure OpenAI R esources\n",
      "Use this option to use an existing Azure OpenAI instance and connect the\n",
      "Semantic K ernel web API to it.PowerShell File  \n",
      "Bash FileConsiderations\n",
      "\n",
      "After working locally, i.e. you cloned the code from the GitHub repo  and have made\n",
      "changes to the code for your needs, you can deploy your changes to Azure as a web\n",
      "application.\n",
      "You can use the standard methods available to deploy an ASP.net web app  in order to\n",
      "do so.\n",
      "Alternatively, you can follow the steps below to manually build and upload your\n",
      "customized version of the Semantic K ernel service to Azure.\n",
      "First, at the command line, go to the '../semantic-kernel/samples/apps/copilot-chat-\n",
      "app/webapi' directory and enter the following command:\n",
      "PowerShell\n",
      "This will create a directory which contains all the files needed for a deployment:\n",
      "Windows Command Prompt\n",
      "Zip the contents of that directory and store the resulting zip file on cloud storage, e.g.\n",
      "Azure Blob Container. Put its URI in the \"P ackage Uri\" field in the web deployment page\n",
      "you access through the \"Deploy to Azure\" buttons or use its URI as the value for the\n",
      "PackageUri parameter of the deployment scripts found on this page .\n",
      "Your deployment will then use your customized deployment package. That package will\n",
      "be used to create a new Azure web app, which will be configured to run your\n",
      "customized version of the Semantic K ernel service.\n",
      "This method is useful for making changes when adding new semantic skills only.\n",
      "dotnet publish CopilotChatApi.csproj  --configuration  Release  --arch x64 --os \n",
      "win\n",
      "../semantic-kernel/samples/apps/copilot-chat-\n",
      "app/webapi/bin/Release/net6. 0/win-x64/publish'\n",
      "2. Publish skills directly to the Semantic Kernel web app\n",
      "service\n",
      "How to add Semantic Skills\n",
      "\n",
      "Learn how to make changes to the\n",
      "Semantic Kernel web app service\n",
      "Article •05/26/2023\n",
      "This guide provides steps to make changes to the skills of a deployed instance of the\n",
      "Semantic K ernel web app. Currently, changing semantic skills can be done without\n",
      "redeploying the web app service but changes to native skills do require re-deployments.\n",
      "This document will guide you through the process of doing both.\n",
      "1. An instance of the Semantic K ernel web app service deployed in your Azure\n",
      "subscription. Y ou can follow the how-to guide here for details.\n",
      "2. Have your web app's name handy. If you used the deployment templates provided\n",
      "with the Chat Copilot, you can find the web app's name by going to the Azure\n",
      "Portal  and selecting the resource group created for your Semantic K ernel web\n",
      "app service. Y our web app's name is the one of the resource listed that ends with\n",
      "\"skweb\".\n",
      "3. Locally tested skills  or planner  ready to be added to your Semantic K ernel web app\n",
      "service.\n",
      "There are two main ways to deploy changes to the Semantic K ernel web app service. If\n",
      "you have been working locally and are ready to deploy your changes to Azure as a new\n",
      "web app service, you can follow the steps in the first section. If you have already\n",
      "deployed your Semantic K ernel web app service and want to make changes to add\n",
      "Semantic skills, you can follow the steps in the second section.Prerequisites\n",
      "How to publish changes to the Semantic Kernel\n",
      "web app service\n",
      "1.Deploying your Chat Copilot App to Azure as a web\n",
      "application\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       " To deploy Semantic Kernel to Azure as a web app service, you can use one of the deployment options to deploy based on your use case and preference. You can use an existing Azure OpenAI instance and connect the Semantic Kernel web API to it. After working locally, i.e. you cloned the code from the GitHub repo and have made changes to the code for your needs, you can deploy your changes to Azure as a web application. You can use the standard methods available to deploy an ASP.net web app in order to do so. Alternatively, you can follow the steps below to manually build and upload your customized version of the Semantic Kernel service to Azure. First, at the command line, go to the '../semantic-kernel/samples/apps/copilot-chat-app/webapi' directory and enter the following command: dotnet publish CopilotChatApi.csproj --configuration Release --arch x64 --os win. This will create a directory which contains all the files needed for a deployment. Zip the contents of that directory and store the resulting zip file on cloud storage, e.g. Azure Blob Container. Put its URI in the \"Package Uri\" field in the web deployment page you access through the \"Deploy to Azure\" buttons or use its URI as the value for the PackageUri parameter of the deployment scripts found on this page. Your deployment will then use your customized deployment package. That package will be used to create a new Azure web app, which will be configured to run your customized version of the Semantic Kernel service."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "question = \"explain how to deploy Semantic Kernel to Azure as a web app service\"\n",
    "sources = search(question, top_k=3)\n",
    "print (sources)\n",
    "response = ask_openai(sources, question)\n",
    "display (Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
