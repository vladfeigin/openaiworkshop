{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DESCRIPTION:\n",
    "    This example shows how to use Azure AI Computer vision SDK to extract dense captions from an image and then use Azure OpenAI GPT3.5 to create a text ad based on the elements identified in the image\n",
    "\n",
    "### REQUIREMENTS:\n",
    "    Create an .env file with your OpenAI API key and save it in the root directory of this project.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") \n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
    "OPENAI_MODEL_NAME = os.getenv(\"OPENAI_MODEL_NAME\")\n",
    "OPENAI_DEPLOYMENT_VERSION = os.getenv(\"OPENAI_DEPLOYMENT_VERSION\")\n",
    "\n",
    "AZURE_COMPUTER_VISION_ENDPOINT = os.getenv(\"AZURE_COMPUTER_VISION_ENDPOINT\")\n",
    "AZURE_COMPUTER_VISION_KEY = os.getenv(\"AZURE_COMPUTER_VISION_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.ai.vision as visionsdk\n",
    "\n",
    "\n",
    "def analyze_image(image_url):\n",
    "    service_options = visionsdk.VisionServiceOptions(AZURE_COMPUTER_VISION_ENDPOINT, AZURE_COMPUTER_VISION_KEY)\n",
    "\n",
    "    # Specify the image file on disk to analyze. sample.jpg is a good example to show most features\n",
    "    # vision_source = visionsdk.VisionSource(filename=\"sample.jpg\")\n",
    "\n",
    "    # Or, instead of the above, specify a publicly accessible image URL to analyze. For example:\n",
    "    vision_source = visionsdk.VisionSource(url=image_url)\n",
    "\n",
    "    analysis_options = visionsdk.ImageAnalysisOptions()\n",
    "\n",
    "    # Mandatory. You must set one or more features to analyze. Here we use the full set of features.\n",
    "    # Note that \"CAPTION\" and \"DENSE_CAPTIONS\" are only supported in Azure GPU regions (East US, France Central,\n",
    "    # Korea Central, North Europe, Southeast Asia, West Europe, West US). Remove \"CAPTION\" and \"DENSE_CAPTIONS\"\n",
    "    # from the list below if your Computer Vision key is not from one of those regions.\n",
    "    analysis_options.features = (\n",
    "        # visionsdk.ImageAnalysisFeature.CROP_SUGGESTIONS |\n",
    "        visionsdk.ImageAnalysisFeature.CAPTION |\n",
    "        visionsdk.ImageAnalysisFeature.DENSE_CAPTIONS |\n",
    "        visionsdk.ImageAnalysisFeature.OBJECTS |\n",
    "        visionsdk.ImageAnalysisFeature.PEOPLE |\n",
    "        visionsdk.ImageAnalysisFeature.TEXT |\n",
    "        visionsdk.ImageAnalysisFeature.TAGS\n",
    "    )\n",
    "\n",
    "    # Optional, and only relevant when you select ImageAnalysisFeature.CROP_SUGGESTIONS.\n",
    "    # Define one or more aspect ratios for the desired cropping. Each aspect ratio needs\n",
    "    # to be in the range [0.75, 1.8]. If you do not set this, the service will return one\n",
    "    # crop suggestion with the aspect ratio it sees fit.\n",
    "    # analysis_options.cropping_aspect_ratios = [0.9, 1.33]\n",
    "\n",
    "    # Optional. Default is \"en\" for English. See https://aka.ms/cv-languages for a list of supported\n",
    "    # language codes and which visual features are supported for each language.\n",
    "    analysis_options.language = \"en\"\n",
    "    analysis_options.model_version = \"latest\"\n",
    "    # Set this to \"true\" to get a gender neutral caption (the default is \"false\").\n",
    "    analysis_options.gender_neutral_caption = True\n",
    "\n",
    "    # Create the image analyzer object\n",
    "    image_analyzer = visionsdk.ImageAnalyzer(service_options, vision_source, analysis_options)\n",
    "\n",
    "    # This call creates the network connection and blocks until Image Analysis results\n",
    "    # return (or an error occurred). Note that there is also an asynchronous (non-blocking)\n",
    "    # version of this method: image_analyzer.analyze_async().\n",
    "    result = image_analyzer.analyze()\n",
    "\n",
    "    # Checks result.\n",
    "    if result.reason == visionsdk.ImageAnalysisResultReason.ANALYZED:\n",
    "\n",
    "        print(\" Image height: {}\".format(result.image_height))\n",
    "        print(\" Image width: {}\".format(result.image_width))\n",
    "        print(\" Model version: {}\".format(result.model_version))\n",
    "\n",
    "        if result.caption is not None:\n",
    "            print(\" Caption:\")\n",
    "            print(\"   '{}', Confidence {:.4f}\".format(result.caption.content, result.caption.confidence))\n",
    "\n",
    "        if result.dense_captions is not None:\n",
    "            print(\" Dense Captions:\")\n",
    "            for caption in result.dense_captions:\n",
    "                print(\"   '{}', {}, Confidence: {:.4f}\".format(caption.content, caption.bounding_box, caption.confidence))\n",
    "\n",
    "        if result.objects is not None:\n",
    "            print(\" Objects:\")\n",
    "            for object in result.objects:\n",
    "                print(\"   '{}', {}, Confidence: {:.4f}\".format(object.name, object.bounding_box, object.confidence))\n",
    "\n",
    "        if result.tags is not None:\n",
    "            print(\" Tags:\")\n",
    "            for tag in result.tags:\n",
    "                print(\"   '{}', Confidence {:.4f}\".format(tag.name, tag.confidence))\n",
    "\n",
    "        if result.people is not None:\n",
    "            print(\" People:\")\n",
    "            for person in result.people:\n",
    "                print(\"   {}, Confidence {:.4f}\".format(person.bounding_box, person.confidence))\n",
    "\n",
    "        if result.crop_suggestions is not None:\n",
    "            print(\" Crop Suggestions:\")\n",
    "            for crop_suggestion in result.crop_suggestions:\n",
    "                print(\"   Aspect ratio {}: Crop suggestion {}\"\n",
    "                      .format(crop_suggestion.aspect_ratio, crop_suggestion.bounding_box))\n",
    "\n",
    "        if result.text is not None:\n",
    "            print(\" Text:\")\n",
    "            for line in result.text.lines:\n",
    "                points_string = \"{\" + \", \".join([str(int(point)) for point in line.bounding_polygon]) + \"}\"\n",
    "                print(\"   Line: '{}', Bounding polygon {}\".format(line.content, points_string))\n",
    "                for word in line.words:\n",
    "                    points_string = \"{\" + \", \".join([str(int(point)) for point in word.bounding_polygon]) + \"}\"\n",
    "                    print(\"     Word: '{}', Bounding polygon {}, Confidence {:.4f}\"\n",
    "                          .format(word.content, points_string, word.confidence))\n",
    "\n",
    "        result_details = visionsdk.ImageAnalysisResultDetails.from_result(result)\n",
    "        print(\" Result details:\")\n",
    "        print(\"   Image ID: {}\".format(result_details.image_id))\n",
    "        print(\"   Result ID: {}\".format(result_details.result_id))\n",
    "        print(\"   Connection URL: {}\".format(result_details.connection_url))\n",
    "        print(\"   JSON result: {}\".format(result_details.json_result))\n",
    "\n",
    "    else:\n",
    "        error_details = visionsdk.ImageAnalysisErrorDetails.from_result(result)\n",
    "        print(\" Analysis failed.\")\n",
    "        print(\"   Error reason: {}\".format(error_details.reason))\n",
    "        print(\"   Error code: {}\".format(error_details.error_code))\n",
    "        print(\"   Error message: {}\".format(error_details.message))\n",
    "        print(\" Did you set the computer vision endpoint and key?\")\n",
    "\n",
    "    return result_details.json_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze a picture using Azure Cognitve services to extract text from a picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Image height: 1000\n",
      " Image width: 1000\n",
      " Model version: 2023-02-01-preview\n",
      " Caption:\n",
      "   'a person with curly hair wearing jeans and a blue shirt', Confidence 0.7689\n",
      " Dense Captions:\n",
      "   'a person with curly hair wearing jeans and a blue shirt', Rectangle(x=0, y=0, w=1000, h=1000), Confidence: 0.7689\n",
      "   'a person wearing a blue shirt and jeans', Rectangle(x=309, y=16, w=386, h=974), Confidence: 0.7428\n",
      "   'a white belt with a circle on it', Rectangle(x=463, y=521, w=60, h=59), Confidence: 0.7001\n",
      "   'a person with curly hair', Rectangle(x=331, y=12, w=291, h=286), Confidence: 0.7511\n",
      "   'a person wearing a blue shirt', Rectangle(x=295, y=203, w=376, h=395), Confidence: 0.7504\n",
      "   'a close-up of a person's legs', Rectangle(x=335, y=505, w=350, h=487), Confidence: 0.8434\n",
      "   'a person with curly hair wearing jeans and a blue shirt', Rectangle(x=0, y=0, w=977, h=977), Confidence: 0.7781\n",
      "   'a close up of a belt', Rectangle(x=386, y=505, w=216, h=77), Confidence: 0.8305\n",
      "   'a hand with a ring on it', Rectangle(x=572, y=668, w=87, h=116), Confidence: 0.7499\n",
      "   'a close up of a blue jean jacket', Rectangle(x=425, y=242, w=86, h=281), Confidence: 0.7255\n",
      " Objects:\n",
      "   'person', Rectangle(x=282, y=39, w=427, h=934), Confidence: 0.8570\n",
      " Tags:\n",
      "   'clothing', Confidence 0.9962\n",
      "   'person', Confidence 0.9907\n",
      "   'jean', Confidence 0.9764\n",
      "   'denim', Confidence 0.9678\n",
      "   'pocket', Confidence 0.9537\n",
      "   'casual dress', Confidence 0.9485\n",
      "   'shirt', Confidence 0.9051\n",
      "   'sleeve', Confidence 0.9043\n",
      "   'trousers', Confidence 0.8898\n",
      "   'top', Confidence 0.8877\n",
      "   'human face', Confidence 0.8772\n",
      "   'collar', Confidence 0.8705\n",
      "   'blouse', Confidence 0.8548\n",
      "   'belt', Confidence 0.8470\n",
      "   'button', Confidence 0.8429\n",
      "   'jeans', Confidence 0.7610\n",
      "   'blue', Confidence 0.7602\n",
      " People:\n",
      "   Rectangle(x=299, y=8, w=428, h=990), Confidence 0.8577\n",
      "   Rectangle(x=337, y=379, w=339, h=245), Confidence 0.0017\n",
      " Text:\n",
      " Result details:\n",
      "   Image ID: https://www.tradeinn.com/f/13738/137387495/levis---essential-western-long-sleeve-shirt.jpg\n",
      "   Result ID: 06cf4d49-fae5-431f-8a3f-8e793f255303\n",
      "   Connection URL: https://computervisiondenisa.cognitiveservices.azure.com/computervision/imageanalysis:analyze?api-version=2023-02-01-preview&features=tags%2Ccaption%2CdenseCaptions%2Cobjects%2Cpeople%2Cread&gender-neutral-caption=true&language=en&model-version=latest\n",
      "   JSON result: {\"captionResult\":{\"text\":\"a person with curly hair wearing jeans and a blue shirt\",\"confidence\":0.7689482569694519},\"objectsResult\":{\"values\":[{\"boundingBox\":{\"x\":282,\"y\":39,\"w\":427,\"h\":934},\"tags\":[{\"name\":\"person\",\"confidence\":0.857}]}]},\"readResult\":{\"stringIndexType\":\"TextElements\",\"content\":\"\",\"pages\":[{\"height\":1000.0,\"width\":1000.0,\"angle\":0.0,\"pageNumber\":1,\"words\":[],\"spans\":[{\"offset\":0,\"length\":0}],\"lines\":[]}],\"styles\":[],\"modelVersion\":\"2022-04-30\"},\"denseCaptionsResult\":{\"values\":[{\"text\":\"a person with curly hair wearing jeans and a blue shirt\",\"confidence\":0.7689482569694519,\"boundingBox\":{\"x\":0,\"y\":0,\"w\":1000,\"h\":1000}},{\"text\":\"a person wearing a blue shirt and jeans\",\"confidence\":0.7428114414215088,\"boundingBox\":{\"x\":309,\"y\":16,\"w\":386,\"h\":974}},{\"text\":\"a white belt with a circle on it\",\"confidence\":0.7001189589500427,\"boundingBox\":{\"x\":463,\"y\":521,\"w\":60,\"h\":59}},{\"text\":\"a person with curly hair\",\"confidence\":0.7510658502578735,\"boundingBox\":{\"x\":331,\"y\":12,\"w\":291,\"h\":286}},{\"text\":\"a person wearing a blue shirt\",\"confidence\":0.7503830194473267,\"boundingBox\":{\"x\":295,\"y\":203,\"w\":376,\"h\":395}},{\"text\":\"a close-up of a person's legs\",\"confidence\":0.8434238433837891,\"boundingBox\":{\"x\":335,\"y\":505,\"w\":350,\"h\":487}},{\"text\":\"a person with curly hair wearing jeans and a blue shirt\",\"confidence\":0.7780935764312744,\"boundingBox\":{\"x\":0,\"y\":0,\"w\":977,\"h\":977}},{\"text\":\"a close up of a belt\",\"confidence\":0.830508828163147,\"boundingBox\":{\"x\":386,\"y\":505,\"w\":216,\"h\":77}},{\"text\":\"a hand with a ring on it\",\"confidence\":0.7498835921287537,\"boundingBox\":{\"x\":572,\"y\":668,\"w\":87,\"h\":116}},{\"text\":\"a close up of a blue jean jacket\",\"confidence\":0.7254947423934937,\"boundingBox\":{\"x\":425,\"y\":242,\"w\":86,\"h\":281}}]},\"modelVersion\":\"2023-02-01-preview\",\"metadata\":{\"width\":1000,\"height\":1000},\"tagsResult\":{\"values\":[{\"name\":\"clothing\",\"confidence\":0.9961915016174316},{\"name\":\"person\",\"confidence\":0.9906636476516724},{\"name\":\"jean\",\"confidence\":0.9763616323471069},{\"name\":\"denim\",\"confidence\":0.9677985906600952},{\"name\":\"pocket\",\"confidence\":0.9537438154220581},{\"name\":\"casual dress\",\"confidence\":0.9484825134277344},{\"name\":\"shirt\",\"confidence\":0.90506911277771},{\"name\":\"sleeve\",\"confidence\":0.904308557510376},{\"name\":\"trousers\",\"confidence\":0.8898420333862305},{\"name\":\"top\",\"confidence\":0.8877418041229248},{\"name\":\"human face\",\"confidence\":0.8771964311599731},{\"name\":\"collar\",\"confidence\":0.8705234527587891},{\"name\":\"blouse\",\"confidence\":0.8548309803009033},{\"name\":\"belt\",\"confidence\":0.8470033407211304},{\"name\":\"button\",\"confidence\":0.8428936004638672},{\"name\":\"jeans\",\"confidence\":0.7610437870025635},{\"name\":\"blue\",\"confidence\":0.7602041363716125}]},\"peopleResult\":{\"values\":[{\"boundingBox\":{\"x\":299,\"y\":8,\"w\":428,\"h\":990},\"confidence\":0.8577113151550293},{\"boundingBox\":{\"x\":337,\"y\":379,\"w\":339,\"h\":245},\"confidence\":0.0017283597262576222}]}}\n"
     ]
    }
   ],
   "source": [
    "# image_url = \"https://aka.ms/azai/vision/image-analysis-sample.jpg\"\n",
    "image_url = \"https://www.tradeinn.com/f/13738/137387495/levis---essential-western-long-sleeve-shirt.jpg\"\n",
    "json_result = analyze_image(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract all dense captions from the json result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a person with curly hair wearing jeans and a blue shirt\n",
      "a person wearing a blue shirt and jeans\n",
      "a white belt with a circle on it\n",
      "a person with curly hair\n",
      "a person wearing a blue shirt\n",
      "a close-up of a person's legs\n",
      "a person with curly hair wearing jeans and a blue shirt\n",
      "a close up of a belt\n",
      "a hand with a ring on it\n",
      "a close up of a blue jean jacket\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# JSON result: {\"captionResult\":{\"text\":\"a person wearing a mask sitting at a table with a laptop\",\"confidence\":1.0},\"objectsResult\":{\"values\":[{\"boundingBox\":{\"x\":303,\"y\":194,\"w\":181,\"h\":223},\"tags\":[{\"name\":\"person\",\"confidence\":0.765}]},{\"boundingBox\":{\"x\":221,\"y\":289,\"w\":159,\"h\":80},\"tags\":[{\"name\":\"Laptop\",\"confidence\":0.574}]}]},\"readResult\":{\"stringIndexType\":\"TextElements\",\"content\":\"Sample text\\nHand writing\\n123 456\",\"pages\":[{\"height\":432.0,\"width\":648.0,\"angle\":0.5729,\"pageNumber\":1,\"words\":[{\"content\":\"Sample\",\"boundingBox\":[542.0,377.0,588.0,377.0,587.0,389.0,542.0,389.0],\"confidence\":0.992,\"span\":{\"offset\":0,\"length\":6}},{\"content\":\"text\",\"boundingBox\":[598.0,377.0,630.0,376.0,630.0,390.0,598.0,389.0],\"confidence\":0.989,\"span\":{\"offset\":7,\"length\":4}},{\"content\":\"Hand\",\"boundingBox\":[540.0,394.0,569.0,394.0,569.0,407.0,540.0,407.0],\"confidence\":0.991,\"span\":{\"offset\":12,\"length\":4}},{\"content\":\"writing\",\"boundingBox\":[573.0,394.0,613.0,395.0,613.0,409.0,573.0,407.0],\"confidence\":0.995,\"span\":{\"offset\":17,\"length\":7}},{\"content\":\"123\",\"boundingBox\":[542.0,412.0,561.0,411.0,561.0,424.0,542.0,424.0],\"confidence\":0.998,\"span\":{\"offset\":25,\"length\":3}},{\"content\":\"456\",\"boundingBox\":[568.0,411.0,590.0,412.0,590.0,424.0,568.0,424.0],\"confidence\":0.998,\"span\":{\"offset\":29,\"length\":3}}],\"spans\":[{\"offset\":0,\"length\":32}],\"lines\":[{\"content\":\"Sample text\",\"boundingBox\":[541.0,376.0,632.0,376.0,632.0,389.0,541.0,389.0],\"spans\":[{\"offset\":0,\"length\":11}]},{\"content\":\"Hand writing\",\"boundingBox\":[540.0,393.0,613.0,395.0,613.0,408.0,540.0,406.0],\"spans\":[{\"offset\":12,\"length\":12}]},{\"content\":\"123 456\",\"boundingBox\":[542.0,411.0,592.0,411.0,592.0,424.0,542.0,423.0],\"spans\":[{\"offset\":25,\"length\":7}]}]}],\"styles\":[],\"modelVersion\":\"2022-04-30\"},\"denseCaptionsResult\":{\"values\":[{\"text\":\"a person wearing a mask sitting at a table with a laptop\",\"confidence\":1.0,\"boundingBox\":{\"x\":0,\"y\":0,\"w\":648,\"h\":432}},{\"text\":\"a person using a laptop\",\"confidence\":1.0,\"boundingBox\":{\"x\":220,\"y\":289,\"w\":144,\"h\":73}},{\"text\":\"a person wearing a colorful face mask\",\"confidence\":1.0,\"boundingBox\":{\"x\":285,\"y\":178,\"w\":202,\"h\":249}},{\"text\":\"a green chair in a room\",\"confidence\":1.0,\"boundingBox\":{\"x\":463,\"y\":160,\"w\":117,\"h\":184}},{\"text\":\"a close-up of a person's hand\",\"confidence\":1.0,\"boundingBox\":{\"x\":217,\"y\":162,\"w\":109,\"h\":180}},{\"text\":\"a person sitting in a chair\",\"confidence\":1.0,\"boundingBox\":{\"x\":418,\"y\":320,\"w\":105,\"h\":109}},{\"text\":\"a blue and green background\",\"confidence\":1.0,\"boundingBox\":{\"x\":456,\"y\":163,\"w\":60,\"h\":155}},{\"text\":\"a close-up of a wooden table\",\"confidence\":1.0,\"boundingBox\":{\"x\":59,\"y\":318,\"w\":55,\"h\":58}},{\"text\":\"a person sitting at a table\",\"confidence\":1.0,\"boundingBox\":{\"x\":287,\"y\":315,\"w\":236,\"h\":113}},{\"text\":\"a close up of a laptop on a table\",\"confidence\":1.0,\"boundingBox\":{\"x\":88,\"y\":338,\"w\":354,\"h\":88}}]},\"modelVersion\":\"2023-02-01-preview\",\"metadata\":{\"width\":648,\"height\":432},\"tagsResult\":{\"values\":[{\"name\":\"furniture\",\"confidence\":0.9880748987197876},{\"name\":\"clothing\",\"confidence\":0.9805002212524414},{\"name\":\"person\",\"confidence\":0.948422908782959},{\"name\":\"houseplant\",\"confidence\":0.9420685768127441},{\"name\":\"desk\",\"confidence\":0.9156692028045654},{\"name\":\"indoor\",\"confidence\":0.9050061106681824},{\"name\":\"computer\",\"confidence\":0.8922904133796692},{\"name\":\"laptop\",\"confidence\":0.8696370124816895},{\"name\":\"sitting\",\"confidence\":0.819450855255127},{\"name\":\"wall\",\"confidence\":0.7605603933334351},{\"name\":\"woman\",\"confidence\":0.7446085214614868},{\"name\":\"table\",\"confidence\":0.6902506351470947},{\"name\":\"plant\",\"confidence\":0.641657829284668},{\"name\":\"using\",\"confidence\":0.5301232933998108}]},\"peopleResult\":{\"values\":[{\"boundingBox\":{\"x\":296,\"y\":181,\"w\":196,\"h\":250},\"confidence\":0.9578750729560852},{\"boundingBox\":{\"x\":2,\"y\":30,\"w\":8,\"h\":23},\"confidence\":0.004669021349400282},{\"boundingBox\":{\"x\":623,\"y\":182,\"w\":24,\"h\":193},\"confidence\":0.0030183952767401934}]}}\n",
    "import json\n",
    "dict = json.loads(json_result)\n",
    "dense_captions = dict[\"denseCaptionsResult\"][\"values\"]\n",
    "\n",
    "text = \"\"\n",
    "for caption in dense_captions:\n",
    "    text += caption[\"text\"] + \"\\n\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a product description from the text extracted from the photo using OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'• The Levi´s® Essential Western Long Sleeve Shirt is a versatile and timeless piece that every young adult should have in their wardrobe.\\n• The shirt is made of a soft and breathable fabric that will keep you comfortable throughout the day.\\n• It is perfect for any occasion, from casual outings to more formal events.\\n• The Western-inspired details give the shirt a unique and stylish look.\\n• The shirt features snap closures and two chest pockets with snap flaps.\\n• It comes in a slim fit that will flatter your figure and enhance your style.\\n• Pair it with jeans for a classic and effortless look.\\n• Get your Levi´s® Essential Western Long Sleeve Shirt today and elevate your wardrobe to the next level!<|im_end|>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's use a sequence of prompts to create a chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "from langchain.llms import AzureOpenAI\n",
    "# Configure OpenAI API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OPENAI_DEPLOYMENT_VERSION\n",
    "openai.api_base = OPENAI_DEPLOYMENT_ENDPOINT\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "llm = AzureOpenAI(deployment_name=OPENAI_DEPLOYMENT_NAME, \n",
    "            model_name=OPENAI_MODEL_NAME, \n",
    "            openai_api_base=OPENAI_DEPLOYMENT_ENDPOINT, \n",
    "            openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "# summarize the video transcript from youtube\n",
    "template = \"\"\"Write a witty product description in a conversational style so young adult shoppers understand what this product does and how it benefits them. Use the following product details to summarize your description:\n",
    "The Product description should not exceed {length} words.\n",
    "Answer in a concise manner only with the product description.\n",
    "Title: Levi´s® Essential Western Long Sleeve Shirt\n",
    "Image description sentences:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"length\"], template=template)\n",
    "prompt_template.format(length=100)\n",
    "\n",
    "chain1=LLMChain(llm=llm,prompt=prompt_template)\n",
    "chain1.run(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
