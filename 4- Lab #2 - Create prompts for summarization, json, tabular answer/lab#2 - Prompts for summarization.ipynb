{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import AzureOpenAI\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display, HTML, JSON\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") \n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
    "OPENAI_MODEL_NAME = os.getenv(\"OPENAI_MODEL_NAME\")\n",
    "OPENAI_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "OPENAI_EMBEDDING_MODEL_NAME = os.getenv(\"OPENAI_EMBEDDING_MODEL_NAME\")\n",
    "OPENAI_DEPLOYMENT_VERSION = os.getenv(\"OPENAI_DEPLOYMENT_VERSION\")\n",
    "\n",
    "# Configure OpenAI API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OPENAI_DEPLOYMENT_VERSION\n",
    "openai.api_base = OPENAI_DEPLOYMENT_ENDPOINT\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_llm(model=\"text-davinci-003\",\n",
    "             deployment_name=\"text-davinci-003\", \n",
    "             temperature=0,\n",
    "             max_tokens=3000,\n",
    "             stop=\"<|im_end|>\", \n",
    "             ):\n",
    "    \n",
    "    llm = AzureOpenAI(deployment_name=deployment_name,  \n",
    "                  model=model,\n",
    "                  temperature=temperature,) \n",
    "    return llm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Text Summarization**\n",
    "\n",
    "There are two types of text summarization: **extractive** and **abstractive**. Extractive summarization involves selecting phrases from the source text and concatenating them to make a summary. In contrast, abstractive summarization aims to generate new phrases and sentences that capture the salient information from the source text. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(llm, prompt_prefix, text_file):\n",
    "    \n",
    "    with open(text_file, 'r') as file:\n",
    "        # read the entire file into a string\n",
    "        data = file.read()\n",
    "\n",
    "    # concatenate the prompt with the data\n",
    "    prompt = prompt_prefix + data\n",
    "    #check the number of tokens in the prompt\n",
    "    num_tokens = llm.get_num_tokens(prompt)\n",
    "    print (f\"Number of tokens in final prompt is: {num_tokens}\")\n",
    "    return llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=init_llm()\n",
    "prompt_prefix = \"Summarize the text below for call center supervisor:\\n\"\n",
    "\n",
    "sum = summarize_text(llm, prompt_prefix, \"./data/bank-call-center-transcript.txt\")\n",
    "display(HTML(sum))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More advanced prompts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in final prompt is: 663\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "The customer service representative successfully greeted the customer politely and professionally, accurately understood the customer's inquiry, provided clear and detailed information in response, asked questions as needed for clarification, discussed both benefits and risks with the customer, explained the tools and resources available to the customer, invited the customer to take further action, offered assistance for the next steps, and ended the conversation on a positive note."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm=init_llm()\n",
    "prompt_prefix = \"\"\" Prepare a summary for the call center supervisor based on the points mentioned below. \n",
    "Please evaluate whether the clerk successfully accomplished the following tasks:\n",
    "\n",
    "Greeting the customer politely and professionally.\n",
    "Accurately understanding the customer's inquiry.\n",
    "Providing clear and detailed information in response.\n",
    "Asking questions as needed for clarification.\n",
    "Discussing both benefits and risks with the customer.\n",
    "Explaining the tools and resources available to the customer.\n",
    "Inviting the customer to take further action.\n",
    "Offering assistance for the next steps.\n",
    "Ending the conversation on a positive note.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sum = summarize_text(llm, prompt_prefix, \"./data/bank-call-center-transcript.txt\")\n",
    "display(HTML(sum))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output in tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in final prompt is: 695\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <tr>\n",
       "    <th>Evaluation Criteria</th>\n",
       "    <th>Performance</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Did the clerk greet the customer in a polite and professional manner?</td>\n",
       "    <td style=\"background-color:green;\">Yes</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Did the clerk began the conversation on a negative note?</td>\n",
       "    <td style=\"background-color:green;\">No</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Did the clerk understand the customer's inquiry?</td>\n",
       "    <td style=\"background-color:green;\">Yes</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Did the clerk provide clear and detailed information?</td>\n",
       "    <td style=\"background-color:green;\">Yes</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Did the clerk ask questions to clarify the situation?</td>\n",
       "    <td style=\"background-color:green;\">Yes</"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "llm=init_llm()\n",
    "prompt_prefix = \"\"\"Please compile a summary of the following information for the attention of the \n",
    "call center supervisor.\n",
    "Present the output in the form of an HTML table, with each item on a separate row.\n",
    "\n",
    "Assign a color code to each item based on the clerk's performance - \n",
    "items that were successfully addressed should be marked in green, \n",
    "whereas items that were not met should be highlighted in red.\n",
    "\n",
    "Here are the evaluation criteria to consider:\n",
    "\n",
    "Did the clerk greet the customer in a polite and professional manner?\n",
    "Did the clerk began the conversation on a negative note?\n",
    "Did the clerk understand the customer's inquiry?\n",
    "Did the clerk provide clear and detailed information?\n",
    "Did the clerk ask questions to clarify the situation?\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "res = summarize_text(llm, prompt_prefix, \"./data/bank-call-center-transcript.txt\")\n",
    "display(HTML(res.strip()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in final prompt is: 847\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "Ask Clarifying Questions": "Yes",
       "Discuss the Benefits and Risks": "Yes",
       "End on a Positive Note": "Yes",
       "Explain Available Tools and Resources": "Yes",
       "Greet the Customer Politely and Professionally": "Yes",
       "Invite Further Action": "Yes",
       "Offer to Assist with Next Steps": "Yes",
       "Provide Clear and Detailed Information": "Yes",
       "Understand the Customer's Inquiry": "Yes"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm=init_llm()\n",
    "prompt_prefix = \"\"\"\"Prepare a summary of the following points for the call center supervisor. \n",
    "The output should be presented in JSON format, adhering to the following schema:\n",
    "\n",
    "{\n",
    "    \"Greet the Customer Politely and Professionally\": \"Yes/No\",\n",
    "    \"Understand the Customer's Inquiry\": \"Yes/No\",\n",
    "    \"Provide Clear and Detailed Information\": \"Yes/No\",\n",
    "    \"Ask Clarifying Questions\": \"Yes/No\",\n",
    "    \"Discuss the Benefits and Risks\": \"Yes/No\",\n",
    "    \"Explain Available Tools and Resources\": \"Yes/No\",\n",
    "    \"Invite Further Action\": \"Yes/No\",\n",
    "    \"Offer to Assist with Next Steps\": \"Yes/No\",\n",
    "    \"End on a Positive Note\": \"Yes/No\"\n",
    "}\n",
    "\n",
    "Please evaluate the clerk's performance based on the following points:\n",
    "\n",
    "Did the clerk greet the customer in a polite and professional manner?\n",
    "Did the clerk comprehend the customer's inquiry accurately?\n",
    "Did the clerk provide comprehensive and clear information?\n",
    "Did the clerk ask relevant questions to clarify the customer's situation?\n",
    "Did the clerk explain the benefits and potential risks to the customer?\n",
    "Did the clerk detail the tools and resources available to the customer?\n",
    "Did the clerk encourage the customer to take further action?\n",
    "Did the clerk offer assistance with proceeding to the next steps?\n",
    "Did the clerk end the interaction on a positive and upbeat note?\"\n",
    "\"\"\"\n",
    "\n",
    "res = summarize_text(llm, prompt_prefix, \"./data/bank-call-center-transcript.txt\")\n",
    "display(JSON(json.loads(res)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
