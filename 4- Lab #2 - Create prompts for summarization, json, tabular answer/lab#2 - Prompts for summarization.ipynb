{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import AzureOpenAI\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display, HTML, JSON\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") \n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
    "OPENAI_MODEL_NAME = os.getenv(\"OPENAI_MODEL_NAME\")\n",
    "OPENAI_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "OPENAI_EMBEDDING_MODEL_NAME = os.getenv(\"OPENAI_EMBEDDING_MODEL_NAME\")\n",
    "OPENAI_DEPLOYMENT_VERSION = os.getenv(\"OPENAI_DEPLOYMENT_VERSION\")\n",
    "\n",
    "# Configure OpenAI API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OPENAI_DEPLOYMENT_VERSION\n",
    "openai.api_base = OPENAI_DEPLOYMENT_ENDPOINT\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_llm(model=\"text-davinci-003\",\n",
    "             deployment_name=\"text-davinci-003\", \n",
    "             temperature=0,\n",
    "             max_tokens=3000,\n",
    "             stop=\"<|im_end|>\", \n",
    "             ):\n",
    "    \n",
    "    llm = AzureOpenAI(deployment_name=deployment_name,  \n",
    "                  model=model,\n",
    "                  temperature=temperature,) \n",
    "    return llm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Text Summarization**\n",
    "\n",
    "There are two types of text summarization: **extractive** and **abstractive**. Extractive summarization involves selecting phrases from the source text and concatenating them to make a summary. In contrast, abstractive summarization aims to generate new phrases and sentences that capture the salient information from the source text. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(llm, prompt_prefix, text_file):\n",
    "    \n",
    "    with open(text_file, 'r') as file:\n",
    "        # read the entire file into a string\n",
    "        data = file.read()\n",
    "\n",
    "    # concatenate the prompt with the data\n",
    "    prompt = prompt_prefix + data\n",
    "    #check the number of tokens in the prompt\n",
    "    num_tokens = llm.get_num_tokens(prompt)\n",
    "    print (f\"Number of tokens in final prompt is: {num_tokens}\")\n",
    "    return llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=init_llm()\n",
    "prompt_prefix = \"Summarize the text below for call center supervisor:\\n\"\n",
    "\n",
    "sum = summarize_text(llm, prompt_prefix, \"./data/bank-call-center-transcript.txt\")\n",
    "display(HTML(sum))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More advanced prompts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=init_llm()\n",
    "prompt_prefix = \"\"\" Summarize the text below for call center supervisor.\\n \n",
    "Did the clerk meet all the items below: \\n\n",
    "\n",
    "1.Greet the Customer Politely and Professionally \\n\n",
    "2.Understand the Customer's Inquiry \\n\n",
    "3.Provide Clear and Detailed Information \\n\n",
    "4.Ask Clarifying Questions \\n\n",
    "5.Discuss the Benefits and Risks \\n\n",
    "6.Explain Available Tools and Resources \\n\n",
    "7.Invite Further Action \\n\n",
    "8.Offer to Assist with Next Steps \\n\n",
    "9.End on a Positive Note \\n\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sum = summarize_text(llm, prompt_prefix, \"./data/bank-call-center-transcript.txt\")\n",
    "display(HTML(sum))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output in tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in final prompt is: 699\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<table>\n",
       "  <tr>\n",
       "    <th>Item</th>\n",
       "    <th>Did Clerk Meet?</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Greet the Customer Politely and Professionally</td>\n",
       "    <td style=\"color:green;\">Yes</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Understand the Customer's Inquiry</td>\n",
       "    <td style=\"color:green;\">Yes</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Provide Clear and Detailed Information</td>\n",
       "    <td style=\"color:green;\">Yes</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Ask Clarifying Questions</td>\n",
       "    <td style=\"color:green;\">Yes</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Discuss the Benefits and Risks</td>\n",
       "    <td style=\"color:green;\">Yes</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Explain Available Tools and Resources</td>\n",
       "    <td style"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "llm=init_llm()\n",
    "prompt_prefix = \"\"\"Summarize the text below for call center supervisor.\\n \n",
    "Provide the output in HTML format in tabular represenation, one line for each item.\\n\n",
    "The items clerk met mark with green color, the items the clerk didn't meet mark with red color.\\n\n",
    "\n",
    "Did the clerk meet all the items below:\\n\n",
    "\n",
    "1.Greet the Customer Politely and Professionally\\n\n",
    "2.Understand the Customer's Inquiry\\n\n",
    "3.Provide Clear and Detailed Information\\n\n",
    "4.Ask Clarifying Questions\\n\n",
    "5.Discuss the Benefits and Risks\\n\n",
    "6.Explain Available Tools and Resources\\n\n",
    "7.Invite Further Action\\n\n",
    "8.Offer to Assist with Next Steps\\n\n",
    "9.End on a Positive Note\\n\n",
    "\"\"\"\n",
    "\n",
    "res = summarize_text(llm, prompt_prefix, \"./data/bank-call-center-transcript.txt\")\n",
    "display(HTML(res))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in final prompt is: 807\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "Ask Clarifying Questions": "Yes",
       "Discuss the Benefits and Risks": "Yes",
       "End on a Positive Note": "Yes",
       "Explain Available Tools and Resources": "Yes",
       "Greet the Customer Politely and Professionally": "Yes",
       "Invite Further Action": "Yes",
       "Offer to Assist with Next Steps": "Yes",
       "Provide Clear and Detailed Information": "Yes",
       "Understand the Customer's Inquiry": "Yes"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm=init_llm()\n",
    "prompt_prefix = \"\"\"Summarize the text below for call center supervisor.\\n \n",
    "Provide the output in JSON format with schema as below:\\n\n",
    "\n",
    "{\n",
    "    \"Greet the Customer Politely and Professionally\": \"Yes/No\",\n",
    "    \"Understand the Customer's Inquiry\": \"Yes/No\",\n",
    "    \"Provide Clear and Detailed Information\": \"Yes/No\",\n",
    "    \"Ask Clarifying Questions\": \"Yes/No\",\n",
    "    \"Discuss the Benefits and Risks\": \"Yes/No\",\n",
    "    \"Explain Available Tools and Resources\": \"Yes/No\",\n",
    "    \"Invite Further Action\": \"Yes/No\",\n",
    "    \"Offer to Assist with Next Steps\": \"Yes/No\",\n",
    "    \"End on a Positive Note\": \"Yes/No\"\n",
    "}\n",
    "\n",
    "Did the clerk meet all the items below:\\n\n",
    "\n",
    "1.Greet the Customer Politely and Professionally\\n\n",
    "2.Understand the Customer's Inquiry\\n\n",
    "3.Provide Clear and Detailed Information\\n\n",
    "4.Ask Clarifying Questions\\n\n",
    "5.Discuss the Benefits and Risks\\n\n",
    "6.Explain Available Tools and Resources\\n\n",
    "7.Invite Further Action\\n\n",
    "8.Offer to Assist with Next Steps\\n\n",
    "9.End on a Positive Note\\n\n",
    "\"\"\"\n",
    "\n",
    "res = summarize_text(llm, prompt_prefix, \"./data/bank-call-center-transcript.txt\")\n",
    "display(JSON(json.loads(res)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
