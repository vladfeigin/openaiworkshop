{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling. Calling Multiple Functions.\n",
    "\n",
    "The latest versions of gpt-35-turbo and gpt-4 have been fine-tuned to work with functions and are able to both determine when and how a function should be called.\n",
    "\n",
    "If one or more functions are included in your request, the model will then determine if any of the functions should be called based on the context of the prompt.\n",
    "\n",
    "When the model determines that a function should be called, it will then respond with a JSON object including the arguments for the function.\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/function-calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "from IPython.display import display, HTML, JSON, Markdown\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "\n",
    "# Configure OpenAI API\n",
    "openai.api_type = \"azure\"\n",
    "# The API version required for Function Calling\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_base = OPENAI_DEPLOYMENT_ENDPOINT\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling multiple functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_current_time(location):\n",
    "    try:\n",
    "        # Get the timezone for the city\n",
    "        timezone = pytz.timezone(location)\n",
    "\n",
    "        # Get the current time in the timezone\n",
    "        now = datetime.now(timezone)\n",
    "        current_time = now.strftime(\"%I:%M:%S %p\")\n",
    "\n",
    "        return current_time\n",
    "    except:\n",
    "        return \"Sorry, I couldn't find the timezone for that location.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'08:19:57 AM'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_time(\"America/New_York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def calculator(num1, num2, operator):\n",
    "    if operator == '+':\n",
    "        return str(num1 + num2)\n",
    "    elif operator == '-':\n",
    "        return str(num1 - num2)\n",
    "    elif operator == '*':\n",
    "        return str(num1 * num2)\n",
    "    elif operator == '/':\n",
    "        return str(num1 / num2)\n",
    "    elif operator == '**':\n",
    "        return str(num1 ** num2)\n",
    "    elif operator == 'sqrt':\n",
    "        return str(math.sqrt(num1))\n",
    "    else:\n",
    "        return \"Invalid operator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(calculator(5, 5, '+'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define functions prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_time\",\n",
    "        \"description\": \"Get the current time in a given location\",\n",
    "        \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The location name. The pytz is used to get the timezone for that location. Location names should be in a format like America/New_York, Asia/Bangkok, Europe/London\",\n",
    "                    }\n",
    "                },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"calculator\",\n",
    "        \"description\": \"A simple calculator used to perform basic arithmetic operations\",\n",
    "        \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"num1\": {\"type\": \"number\"},\n",
    "                    \"num2\": {\"type\": \"number\"},\n",
    "                    \"operator\": {\"type\": \"string\", \"enum\": [\"+\", \"-\", \"*\", \"/\", \"**\", \"sqrt\"]},\n",
    "                },\n",
    "            \"required\": [\"num1\", \"num2\", \"operator\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "available_functions = {\n",
    "    \"get_current_time\": get_current_time,\n",
    "    \"calculator\": calculator,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "# helper method used to run validation on the function arguments returned by the model\n",
    "\n",
    "def check_args(function, args):\n",
    "    sig = inspect.signature(function)\n",
    "    print (f\"\"\" function signature {sig}\\n\"\"\")\n",
    "    params = sig.parameters\n",
    "    print (f\"\"\" function parameters {params}\\n\"\"\")\n",
    "\n",
    "    # Check if there are extra arguments\n",
    "    for name in args:\n",
    "        if name not in params:\n",
    "            return False\n",
    "    # Check if the required arguments are provided\n",
    "    for name, param in params.items():\n",
    "        if param.default is param.empty and name not in args:\n",
    "            return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orchestrating function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(messages, functions, available_functions, deployment_id):\n",
    "    \n",
    "    # Step 1: send the conversation and available functions to GPT\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id=deployment_id,\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "    # Step 2: check if GPT wanted to call a function\n",
    "    if response_message.get(\"function_call\"):\n",
    "        print(\"Recommended Function call:\")\n",
    "        print(response_message.get(\"function_call\"))\n",
    "        print()\n",
    "\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "\n",
    "        # verify function exists\n",
    "        if function_name not in available_functions:\n",
    "            return \"Function \" + function_name + \" does not exist\"\n",
    "        function_to_call = available_functions[function_name]\n",
    "\n",
    "        # verify function has correct number of arguments\n",
    "        function_args = json.loads(\n",
    "            response_message[\"function_call\"][\"arguments\"])\n",
    "        if check_args(function_to_call, function_args) is False:\n",
    "            return \"Invalid number of arguments for function: \" + function_name\n",
    "        \n",
    "        #call the function \n",
    "        function_response = function_to_call(**function_args)\n",
    "\n",
    "        print(\"Output of function call:\")\n",
    "        print(function_response)\n",
    "        print()\n",
    "\n",
    "        # Step 4: send the info on the first function call and function response to GPT\n",
    "\n",
    "        # adding assistant response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": response_message[\"role\"],\n",
    "                \"name\": response_message[\"function_call\"][\"name\"],\n",
    "                \"content\": response_message[\"function_call\"][\"arguments\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # adding function response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "\n",
    "        print(\"Messages in second request:\")\n",
    "        for message in messages:\n",
    "            print(message)\n",
    "        print()\n",
    "\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            messages=messages,\n",
    "            deployment_id=deployment_id\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "        return second_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Function call:\n",
      "{\n",
      "  \"name\": \"get_current_time\",\n",
      "  \"arguments\": \"{\\n  \\\"location\\\": \\\"America/New_York\\\"\\n}\"\n",
      "}\n",
      "\n",
      " function signature (location)\n",
      "\n",
      " function parameters OrderedDict([('location', <Parameter \"location\">)])\n",
      "\n",
      "Output of function call:\n",
      "08:26:11 AM\n",
      "\n",
      "Messages in second request:\n",
      "{'role': 'user', 'content': 'What time is it in New York?'}\n",
      "{'role': 'assistant', 'name': 'get_current_time', 'content': '{\\n  \"location\": \"America/New_York\"\\n}'}\n",
      "{'role': 'function', 'name': 'get_current_time', 'content': '08:26:11 AM'}\n",
      "\n",
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"It is currently 08:26 AM in New York.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What time is it in New York?\"}]\n",
    "assistant_response = run_conversation(\n",
    "    messages, functions, available_functions, \"gpt-35-turbo-0613\")\n",
    "print(assistant_response['choices'][0]['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Function call:\n",
      "{\n",
      "  \"name\": \"calculator\",\n",
      "  \"arguments\": \"{\\n  \\\"num1\\\": 73846,\\n  \\\"num2\\\": 12,\\n  \\\"operator\\\": \\\"*\\\"\\n}\"\n",
      "}\n",
      "\n",
      " function signature (num1, num2, operator)\n",
      "\n",
      " function parameters OrderedDict([('num1', <Parameter \"num1\">), ('num2', <Parameter \"num2\">), ('operator', <Parameter \"operator\">)])\n",
      "\n",
      "Output of function call:\n",
      "886152\n",
      "\n",
      "Messages in second request:\n",
      "{'role': 'user', 'content': 'Last month Fabrikam made $73,846 in sales. Based on that, what would the annual run rate be?'}\n",
      "{'role': 'assistant', 'name': 'calculator', 'content': '{\\n  \"num1\": 73846,\\n  \"num2\": 12,\\n  \"operator\": \"*\"\\n}'}\n",
      "{'role': 'function', 'name': 'calculator', 'content': '886152'}\n",
      "\n",
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"The annual run rate would be $886,152.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Last month Fabrikam made $73,846 in sales. Based on that, what would the annual run rate be?\"}\n",
    "]\n",
    "\n",
    "assistant_response = run_conversation(\n",
    "    messages, functions, available_functions, \"gpt-35-turbo-0613\")\n",
    "print(assistant_response['choices'][0]['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
