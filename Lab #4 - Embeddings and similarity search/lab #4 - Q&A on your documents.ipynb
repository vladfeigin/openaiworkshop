{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Environment variables from .env file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.llms import AzureOpenAI\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display, HTML, JSON, Markdown\n",
    "\n",
    "load_dotenv()\n",
    "# env variables that are used by LangChain\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['OPENAI_API_TYPE'] = \"azure\"\n",
    "os.environ['OPENAI_API_VERSION'] = os.getenv(\"OPENAI_DEPLOYMENT_VERSION\")\n",
    "os.environ['OPENAI_API_BASE'] = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "\n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
    "OPENAI_MODEL_NAME = os.getenv(\"OPENAI_MODEL_NAME\")\n",
    "\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_MODEL_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_MODEL_NAME\")\n",
    "\n",
    "# Configure OpenAI API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = os.getenv(\"OPENAI_DEPLOYMENT_VERSION\")\n",
    "openai.api_base = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Init LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_llm(model=OPENAI_MODEL_NAME,\n",
    "             deployment_name=OPENAI_DEPLOYMENT_NAME,\n",
    "             temperature=0,\n",
    "             max_tokens=800,\n",
    "             stop=\"<|im_end|>\",\n",
    "             ):\n",
    "\n",
    "    llm = AzureChatOpenAI(deployment_name=deployment_name,\n",
    "                      model=model,\n",
    "                      temperature=temperature,\n",
    "                      max_tokens=max_tokens,\n",
    "                      model_kwargs={\"stop\": [\"<|im_end|>\"]})\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data, movies reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2532\n"
     ]
    }
   ],
   "source": [
    "file = \"documents/imdb_clean.csv\"\n",
    "loader = CSVLoader(file_path=file)\n",
    "# LangChain Document is created per line in CSV file, no need\n",
    "docs = loader.load()\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "#init embedding model\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME, chunk_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High Level Intro into Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score12=[[0.75606641]], score13=[[0.85867013]], score23=[[0.78012263]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "text1 = \"I like to eat apples\"\n",
    "text2 = \"He bought a new car\"\n",
    "text3 = \"She eats an orange\"\n",
    "\n",
    "emb_text1 = embeddings.embed_query(text1)\n",
    "emb_text2 = embeddings.embed_query(text2)\n",
    "emb_text3 = embeddings.embed_query(text3)\n",
    "\n",
    "#Calculate the similarity between two sentences\n",
    "score12 = cosine_similarity([emb_text1], [emb_text2])\n",
    "score13 = cosine_similarity([emb_text1], [emb_text3])\n",
    "score23 = cosine_similarity([emb_text2], [emb_text3])\n",
    "\n",
    "print(f\"score12={score12}, score13={score13}, score23={score23}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Ex. Try out your own sentences and check the similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create in memory vector store to use along with LLM model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init in-memory vector store\n",
    "# this could take several minutes\n",
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    docs,\n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Similarity Search on the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       ": 0\n",
       "title: The Shawshank Redemption\n",
       "director: Frank Darabont\n",
       "release_year: 1994\n",
       "runtime: 142\n",
       "genre: Drama\n",
       "rating: 9.3\n",
       "metascore: 82\n",
       "gross(M): 28.34"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ": 24\n",
       "title: The Green Mile\n",
       "director: Frank Darabont\n",
       "release_year: 1999\n",
       "runtime: 189\n",
       "genre: Drama\n",
       "rating: 8.6\n",
       "metascore: 61\n",
       "gross(M): 136.8"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ": 24\n",
       "title: The Green Mile\n",
       "director: Frank Darabont\n",
       "release_year: 1999\n",
       "runtime: 189\n",
       "genre: Crime\n",
       "rating: 8.6\n",
       "metascore: 61\n",
       "gross(M): 136.8"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ": 211\n",
       "title: Prisoners\n",
       "director: Denis Villeneuve\n",
       "release_year: 2013\n",
       "runtime: 153\n",
       "genre: Drama\n",
       "rating: 8.1\n",
       "metascore: 70\n",
       "gross(M): 61.0"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       ": 3\n",
       "title: Schindler's List\n",
       "director: Steven Spielberg\n",
       "release_year: 1993\n",
       "runtime: 195\n",
       "genre: Biography\n",
       "rating: 9.0\n",
       "metascore: 95\n",
       "gross(M): 96.9"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qdocs = db.similarity_search(\n",
    "    \"Shawshank redemption\", k=5)\n",
    "for doc in qdocs:\n",
    "    display(Markdown(doc.page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 0\n",
      "title: The Shawshank Redemption\n",
      "director: Frank Darabont\n",
      "release_year: 1994\n",
      "runtime: 142\n",
      "genre: Drama\n",
      "rating: 9.3\n",
      "metascore: 82\n",
      "gross(M): 28.34: 24\n",
      "title: The Green Mile\n",
      "director: Frank Darabont\n",
      "release_year: 1999\n",
      "runtime: 189\n",
      "genre: Drama\n",
      "rating: 8.6\n",
      "metascore: 61\n",
      "gross(M): 136.8: 24\n",
      "title: The Green Mile\n",
      "director: Frank Darabont\n",
      "release_year: 1999\n",
      "runtime: 189\n",
      "genre: Crime\n",
      "rating: 8.6\n",
      "metascore: 61\n",
      "gross(M): 136.8: 211\n",
      "title: Prisoners\n",
      "director: Denis Villeneuve\n",
      "release_year: 2013\n",
      "runtime: 153\n",
      "genre: Drama\n",
      "rating: 8.1\n",
      "metascore: 70\n",
      "gross(M): 61.0: 3\n",
      "title: Schindler's List\n",
      "director: Steven Spielberg\n",
      "release_year: 1993\n",
      "runtime: 195\n",
      "genre: Biography\n",
      "rating: 9.0\n",
      "metascore: 95\n",
      "gross(M): 96.9\n"
     ]
    }
   ],
   "source": [
    "# prepare context for sending to LLM\n",
    "# concatenate all retrieved documents \n",
    "context_for_llm = \"\".join([qdocs[i].page_content for i in range(len(qdocs))])\n",
    "print(context_for_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call LLM to process the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The prevalent movie genre in the provided text is Drama."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import LangChain schema classes for messages\n",
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    ")\n",
    "\n",
    "llm = init_llm()\n",
    "\n",
    "user_query = f\"\"\" Which movie genre is the prevalent in this text: ```{context_for_llm}```?\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You're great movies expert. Answer users question about movies. Answer only based on the provided text dilimited in triple backticks.\")\n",
    "]\n",
    "messages.append(\n",
    "    HumanMessage(content=user_query))\n",
    "\n",
    "answer = llm(messages)\n",
    "\n",
    "display(Markdown(answer.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using LangChain RetrievalQA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a retiever as a vector store\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The prevalent movie genre in this text is Drama."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = qa_stuff.run(user_query)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "There are four movies mentioned in the text: \n",
       "1. The Shawshank Redemption (1994) directed by Frank Darabont, a drama with a runtime of 142 minutes, a rating of 9.3, a metascore of 82, and a gross of 28.34 million dollars. \n",
       "2. The Green Mile (1999) directed by Frank Darabont, a drama with a runtime of 189 minutes, a rating of 8.6, a metascore of 61, and a gross of 136.8 million dollars. \n",
       "3. Prisoners (2013) directed by Denis Villeneuve, a drama with a runtime of 153 minutes, a rating of 8.1, a metascore of 70, and a gross of 61.0 million dollars. \n",
       "4. Schindler's List (1993) directed by Steven Spielberg, a biography with a runtime of 195 minutes, a rating of 9.0, a metascore of 95, and a gross of 96.9 million dollars."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_query = f\" Summarize the movies in the text. Remove duplicated movies: {context_for_llm}?\"\n",
    "response = qa_stuff.run(user_query)\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
