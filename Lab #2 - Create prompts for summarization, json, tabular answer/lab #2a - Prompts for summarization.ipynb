{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Environment variables from .env file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import AzureOpenAI\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from IPython.display import display, HTML, JSON, Markdown\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") \n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
    "OPENAI_MODEL_NAME = os.getenv(\"OPENAI_MODEL_NAME\")\n",
    "OPENAI_DEPLOYMENT_VERSION = os.getenv(\"OPENAI_DEPLOYMENT_VERSION\")\n",
    "\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_MODEL_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_MODEL_NAME\")\n",
    "\n",
    "OPENAI_DAVINCI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DAVINCI_DEPLOYMENT_NAME\")\n",
    "OPENAI_DAVINCI_MODEL_NAME = os.getenv(\"OPENAI_DAVINCI_MODEL_NAME\")\n",
    "\n",
    "# Configure OpenAI API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OPENAI_DEPLOYMENT_VERSION\n",
    "openai.api_base = OPENAI_DEPLOYMENT_ENDPOINT\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_llm(model=OPENAI_DAVINCI_MODEL_NAME,\n",
    "             deployment_name=OPENAI_DAVINCI_DEPLOYMENT_NAME, \n",
    "             temperature=0,\n",
    "             max_tokens=4000,\n",
    "             stop=\"<|im_end|>\", \n",
    "             ):\n",
    "    \n",
    "    llm = AzureOpenAI(deployment_name=deployment_name,  \n",
    "                  model=model,\n",
    "                  temperature=temperature,) \n",
    "    return llm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Prompt engineering techniques**\n",
    "Those techniques are not specific to summarization, but can be used for any task.\n",
    "\n",
    "1. Use delimeters to clearly separate the exact text the model should summarize.\n",
    "\n",
    "    Delimiters could be any kind of punctuation, that separates specific pieces of text. \n",
    "    Tripple quotes, Triple backtics, Triple dashes, Angle brackets, XML tags, etc.\n",
    "\n",
    "2. Ask model for structured output, e.g json, html, etc. If you ask for a json define the structure of the json, e.g. what fields should be in the json.\n",
    "\n",
    "3. Check assumptions required to do the task.\n",
    "\n",
    "4. Few-shot prompting. Provide examples of completing tasks and then ask model to perform the task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Imaginal Bank offers a variety of investment programs with risk management strategies, as well as an online platform to monitor investments, and financial advisors to help customers choose the right program."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using delimiters to clearly separate input text.\n",
    "\n",
    "text = f\"\"\"\n",
    "**Customer**: Hello, my name is John, and I'm a customer of Imaginal Bank.\n",
    "**Clerk**: Hello, John! My name is Sara, and I'm a customer service representative at Imaginal Bank. How can I assist you today?\n",
    "**Customer**: Hi, Sara. I'm interested in your bank's investment programs. \n",
    "              Can you tell me more about them, especially in terms of risk management?\n",
    "\n",
    "**Clerk**: Absolutely, John. We have a few key programs I can highlight.\n",
    "\n",
    "First, there's our 'Balanced Growth Fund'. It's a diversified mutual fund that invests in a mix of equities and bonds to provide both growth and income, reducing risk through diversification. \n",
    "\n",
    "We also have the 'Index Tracker ETF', which is designed to replicate the performance of a specific market index. By spreading investments across the entire index, it inherently reduces the risk associated with individual stocks.\n",
    "\n",
    "Additionally, for those with a lower risk tolerance, we have the 'Secure Income Bond Fund', which focuses on government and high-quality corporate bonds. \n",
    "\n",
    "Our financial advisors are always available to guide you in choosing the right program based on your financial goals and risk tolerance.\n",
    "\n",
    "**Customer**: I see. Could you elaborate on how the Balanced Growth Fund manages risk?\n",
    "\n",
    "**Clerk**: Sure. The Balanced Growth Fund mitigates risk by diversifying investments across a wide range of assets. If one investment performs poorly, it's likely to be offset by other investments that are performing well. Furthermore, our portfolio managers actively manage the fund, adjusting holdings based on changing market conditions to manage risk and enhance returns.\n",
    "\n",
    "**Customer**: Does the bank provide any tools to monitor my investments?\n",
    "\n",
    "**Clerk**: Yes, John. We offer an online platform called 'Imaginal Investor Dashboard'. It provides real-time tracking of your investments, balance updates, and market trends. You can also set up alerts to be notified about significant changes in your portfolio.\n",
    "\n",
    "**Customer**: That sounds quite comprehensive. How can I get started?\n",
    "\n",
    "**Clerk**: You can schedule an appointment with one of our financial advisors. They'll walk you through your options, help you understand your risk tolerance, and guide you in choosing the right investment program. Would you like me to arrange that for you?\n",
    "\n",
    "**Customer**: Yes, please. That would be helpful.\n",
    "\n",
    "**Clerk**: Fantastic, John! Let's get that set up for you...\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\" Summarize the text delimited by triple backticks into single sentence. \n",
    "```{text}```\"\"\"\n",
    "\n",
    "llm=init_llm()\n",
    "sum = llm(prompt)\n",
    "display(Markdown(sum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "John, a customer of Imaginal Bank, asked Sara, a customer service representative, about the bank's investment programs and was provided with information about the Balanced Growth Fund, Index Tracker ETF, and Secure Income Bond Fund, as well as the Imaginal Investor Dashboard, and was offered an appointment with a financial advisor."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the specific conditions/assumptions in the text\n",
    "\n",
    "prompt = f\"\"\" You will be provided with a text delimited by triple quotes. \n",
    "If it's contains utterances of a Customer and a Clerk, summarize the text into single sentence.\n",
    "If the text does not contain utterances of a Customer and a Clerk, \n",
    "then just write 'No customer and clerk utterances found'.\n",
    "\\\"\\\"\\\" {text}  \\\"\\\"\\\"\n",
    "\"\"\"\n",
    "llm=init_llm()\n",
    "sum = llm(prompt)\n",
    "display(Markdown(sum))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "No customer and clerk utterances found."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the specific conditions/assumptions in the text\n",
    "\n",
    "text = f\"\"\"just a text\"\"\"\n",
    "\n",
    "prompt = f\"\"\" You will be provided with a text delimited by triple quotes. If it's contains utterances of a Customer and a Clerk, summarize the text into single sentence. If the text does not contain utterances of a Customer and a Clerk, \n",
    "then just write 'No customer and clerk utterances found'.\n",
    "\\\"\\\"\\\" {text}  \\\"\\\"\\\"\n",
    "\"\"\"\n",
    "llm=init_llm()\n",
    "sum = llm(prompt)\n",
    "display(Markdown(sum))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Give the model time to think\n",
    "\n",
    "Very useful technique is to give the model time to think by specifying the strict steps (sub-tasks) to complete the task and asking for output in a specific format. This is a very powerful technique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Summary: Imaginal Bank offers a variety of investment programs with different levels of risk management, as well as an online platform to monitor investments, and financial advisors to help customers choose the right program.\n",
       "Translated summary: A Imaginal Bank oferece uma variedade de programas de investimento com diferentes n√≠veis de gerenciamento de risco, bem como uma plataforma online para monitorar investimentos e consultores financeiros para ajudar os clientes a escolher o programa certo.\n",
       "Customer questions: \n",
       "1. Can you tell me more about Imaginal Bank's investment programs, especially in terms of risk management?\n",
       "2. Could you elaborate on how the Balanced Growth Fund manages risk?\n",
       "3. Does the bank provide any tools to monitor my investments?\n",
       "4. How can I get started?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "**Customer**: Hello, my name is John, and I'm a customer of Imaginal Bank.\n",
    "**Clerk**: Hello, John! My name is Sara, and I'm a customer service representative at Imaginal Bank. How can I assist you today?\n",
    "**Customer**: Hi, Sara. I'm interested in your bank's investment programs. \n",
    "              Can you tell me more about them, especially in terms of risk management?\n",
    "\n",
    "**Clerk**: Absolutely, John. We have a few key programs I can highlight.\n",
    "\n",
    "First, there's our 'Balanced Growth Fund'. It's a diversified mutual fund that invests in a mix of equities and bonds to provide both growth and income, reducing risk through diversification. \n",
    "\n",
    "We also have the 'Index Tracker ETF', which is designed to replicate the performance of a specific market index. By spreading investments across the entire index, it inherently reduces the risk associated with individual stocks.\n",
    "\n",
    "Additionally, for those with a lower risk tolerance, we have the 'Secure Income Bond Fund', which focuses on government and high-quality corporate bonds. \n",
    "\n",
    "Our financial advisors are always available to guide you in choosing the right program based on your financial goals and risk tolerance.\n",
    "\n",
    "**Customer**: I see. Could you elaborate on how the Balanced Growth Fund manages risk?\n",
    "\n",
    "**Clerk**: Sure. The Balanced Growth Fund mitigates risk by diversifying investments across a wide range of assets. If one investment performs poorly, it's likely to be offset by other investments that are performing well. Furthermore, our portfolio managers actively manage the fund, adjusting holdings based on changing market conditions to manage risk and enhance returns.\n",
    "\n",
    "**Customer**: Does the bank provide any tools to monitor my investments?\n",
    "\n",
    "**Clerk**: Yes, John. We offer an online platform called 'Imaginal Investor Dashboard'. It provides real-time tracking of your investments, balance updates, and market trends. You can also set up alerts to be notified about significant changes in your portfolio.\n",
    "\n",
    "**Customer**: That sounds quite comprehensive. How can I get started?\n",
    "\n",
    "**Clerk**: You can schedule an appointment with one of our financial advisors. They'll walk you through your options, help you understand your risk tolerance, and guide you in choosing the right investment program. Would you like me to arrange that for you?\n",
    "\n",
    "**Customer**: Yes, please. That would be helpful.\n",
    "\n",
    "**Clerk**: Fantastic, John! Let's get that set up for you...\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\" Your task is to perform the following actions:\n",
    "1 - Summarize the text delimited by triple backticks into single sentence.\n",
    "2 - Translate the summary into Portuguese.\n",
    "3 - List the Customer questions.\n",
    "\n",
    "Use the following output format:\n",
    "Summary: <summary>\n",
    "Translated summary: <portuguese summary>\n",
    "Customer questions: <enumerated customer questions>\n",
    "\n",
    "Text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "llm=init_llm()\n",
    "sum = llm(prompt)\n",
    "display(Markdown(sum))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's do some math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "Correct."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = f\"\"\" Determine id the sudent's solution is correct or not.\n",
    "Question: When I was 2 years old my sister was twice my age. I'm now 40 years old how old is my sister now? \n",
    "\n",
    "Student's answer: The sister is now 80 years old.\n",
    "\"\"\"\n",
    "\n",
    "llm=init_llm()\n",
    "sum = llm(prompt)\n",
    "display(HTML(sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ask model to do its own solution and then to compare both solutions and coclude which is correct.\n",
    " Define the task as a list of sub-tasks and ask the model to perform them in a specific order (splitting the task into sub-tasks technique). \n",
    " Then ask the model to compare its own solution with the solution provided by the model and conclude which is correct.\n",
    " Ask model to share it reasoning for the conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Actual solution steps: \n",
       "1. When the student was 2 years old, their sister was twice their age, so their sister was 4 years old. \n",
       "2. Since the student is now 40 years old, their sister has aged 40 years since then. \n",
       "3. Therefore, their sister is now 40 + 4 = 44 years old. \n",
       "\n",
       "Student's solution: The sister is now 80 years old.\n",
       "Student's solution is correct: False"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Question = f\"\"\"When I was 2 years old my sister was twice of my age . I'm now 40 years old, how old is my sister now?\"\"\"\n",
    "Student_Solution = f\"\"\" The sister is now 80 years old.\"\"\"\n",
    "\n",
    "prompt = f\"\"\" Determine if the Student's Solution for the Question is correct or not.\n",
    "To solve the problem do the following:\n",
    "1 - First, work out your OWN solution to the problem. Evaluate your final result to make sure it is correct and adheres to the question's conditions. \n",
    "2 - Second, compare your solution to the student's solution and evaluate if the student's solution is correct or not.\n",
    "Don't decide if the student's solution is correct until you have done the problem yourself.\n",
    "\n",
    "\n",
    "Use the following output format:\n",
    "Actual solution steps: <your own solution steps>\n",
    "Student's solution: <student's solution>\n",
    "Student's solution is correct: <true/false>\n",
    "\n",
    "\n",
    "Student's Solution: ```{Student_Solution}```\n",
    "Question: ```{Question}```\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "llm=init_llm()\n",
    "sum = llm(prompt)\n",
    "display(Markdown(sum))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Hallucinations and how to avoid them\n",
    "\n",
    "Hallucination is when the model generates text that is not supported by the input.\n",
    "To reduce hallucinations, use the techniques listed above, and strictly instruct the model to find the relevant information in the input text. \n",
    "If the information is not in the input, instruct the model to generate a specific output, e.g. \"I don't know the answer to this question\". "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative Prompt Development\n",
    "Prompt engineering is an iterative process. You almost never get the prompt right the first time.\n",
    "You start with the idea, then you implement the prompt, get the experimental resuslts, do the Error Analysis and iterate again.\n",
    "\n",
    "**Try -> Analyze -> Clarify Instructions -> Try again**\n",
    "\n",
    "In more advanced phases refine prompts with a batch of examples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function\n",
    "#Note that this functions calculates the number of tokens in the prompt\n",
    "def summarize_text(llm, prompt_prefix, text_file):\n",
    "    \n",
    "    with open(text_file, 'r') as file:\n",
    "        # read the entire file into a string\n",
    "        data = file.read()\n",
    "\n",
    "    # concatenate the prompt with the data\n",
    "    prompt = prompt_prefix + data\n",
    "    #check the number of tokens in the prompt\n",
    "    num_tokens = llm.get_num_tokens(prompt)\n",
    "    print (f\"Number of tokens in final prompt is: {num_tokens}\")\n",
    "    return llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in final prompt is: 554\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "John, a customer of Imaginal Bank, is interested in the bank's investment programs and inquires about risk management. The customer service representative explains the three main programs offered by the bank and how they manage risk. The representative also mentions the Imaginal Investor Dashboard, an online platform that provides real-time tracking of investments, balance updates, and market trends. Finally, the representative offers to arrange an appointment with a financial advisor to help John choose the right investment program."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm=init_llm()\n",
    "prompt_prefix = \"Summarize the text below for a call center supervisor:\\n\"\n",
    "\n",
    "sum = summarize_text(llm, prompt_prefix, \"./data/bank-call-center-transcript.txt\")\n",
    "display(Markdown(sum))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More advanced prompts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in final prompt is: 663\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "The customer service representative, Sara, successfully accomplished all the tasks. She greeted the customer politely and professionally, accurately understood the customer's inquiry, provided clear and detailed information in response, asked questions as needed for clarification, discussed both benefits and risks with the customer, explained the tools and resources available to the customer, invited the customer to take further action, offered assistance for the next steps, and ended the conversation on a positive note."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm=init_llm()\n",
    "prompt_prefix = \"\"\" Prepare a summary for the call center supervisor based on the points mentioned below. \n",
    "Please evaluate whether the clerk successfully accomplished the following tasks:\n",
    "\n",
    "Greeting the customer politely and professionally.\n",
    "Accurately understanding the customer's inquiry.\n",
    "Providing clear and detailed information in response.\n",
    "Asking questions as needed for clarification.\n",
    "Discussing both benefits and risks with the customer.\n",
    "Explaining the tools and resources available to the customer.\n",
    "Inviting the customer to take further action.\n",
    "Offering assistance for the next steps.\n",
    "Ending the conversation on a positive note.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sum = summarize_text(llm, prompt_prefix, \"./data/bank-call-center-transcript.txt\")\n",
    "display(Markdown(sum))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output in tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in final prompt is: 695\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <tr>\n",
       "    <th>Evaluation Criteria</th>\n",
       "    <th>Result</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Did the clerk greet the customer in a polite and professional manner?</td>\n",
       "    <td style=\"background-color:green;\">Yes</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Did the clerk begin the conversation on a negative note?</td>\n",
       "    <td style=\"background-color:green;\">No</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Did the clerk understand the customer's inquiry?</td>\n",
       "    <td style=\"background-color:green;\">Yes</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Did the clerk provide clear and detailed information?</td>\n",
       "    <td style=\"background-color:green;\">Yes</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Did the clerk ask questions to clarify the situation?</td>\n",
       "    <td style=\"background-color:green;\">Yes</"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm=init_llm()\n",
    "prompt_prefix = \"\"\"Summarize the following information for the attention of the \n",
    "call center supervisor.\n",
    "Present the output in the form of an HTML table, with each item on a separate row.\n",
    "\n",
    "Assign a color code to each item based on the clerk's performance - \n",
    "items that were successfully addressed should be marked in green, \n",
    "whereas items that were not met should be highlighted in red.\n",
    "\n",
    "Here are the evaluation criterias to consider:\n",
    "\n",
    "Did the clerk greet the customer in a polite and professional manner?\n",
    "Did the clerk begin the conversation on a negative note?\n",
    "Did the clerk understand the customer's inquiry?\n",
    "Did the clerk provide clear and detailed information?\n",
    "Did the clerk ask questions to clarify the situation?\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "res = summarize_text(llm, prompt_prefix, \"./data/bank-call-center-transcript.txt\")\n",
    "display(HTML(res.strip()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in final prompt is: 847\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "Ask Clarifying Questions": "Yes",
       "Discuss the Benefits and Risks": "Yes",
       "End on a Positive Note": "Yes",
       "Explain Available Tools and Resources": "Yes",
       "Greet the Customer Politely and Professionally": "Yes",
       "Invite Further Action": "Yes",
       "Offer to Assist with Next Steps": "Yes",
       "Provide Clear and Detailed Information": "Yes",
       "Understand the Customer's Inquiry": "Yes"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm=init_llm()\n",
    "prompt_prefix = \"\"\"\"Prepare a summary of the following points for the call center supervisor. \n",
    "The output should be presented in JSON format, adhering to the following schema:\n",
    "\n",
    "{\n",
    "    \"Greet the Customer Politely and Professionally\": \"Yes/No\",\n",
    "    \"Understand the Customer's Inquiry\": \"Yes/No\",\n",
    "    \"Provide Clear and Detailed Information\": \"Yes/No\",\n",
    "    \"Ask Clarifying Questions\": \"Yes/No\",\n",
    "    \"Discuss the Benefits and Risks\": \"Yes/No\",\n",
    "    \"Explain Available Tools and Resources\": \"Yes/No\",\n",
    "    \"Invite Further Action\": \"Yes/No\",\n",
    "    \"Offer to Assist with Next Steps\": \"Yes/No\",\n",
    "    \"End on a Positive Note\": \"Yes/No\"\n",
    "}\n",
    "\n",
    "Please evaluate the clerk's performance based on the following points:\n",
    "\n",
    "Did the clerk greet the customer in a polite and professional manner?\n",
    "Did the clerk comprehend the customer's inquiry accurately?\n",
    "Did the clerk provide comprehensive and clear information?\n",
    "Did the clerk ask relevant questions to clarify the customer's situation?\n",
    "Did the clerk explain the benefits and potential risks to the customer?\n",
    "Did the clerk detail the tools and resources available to the customer?\n",
    "Did the clerk encourage the customer to take further action?\n",
    "Did the clerk offer assistance with proceeding to the next steps?\n",
    "Did the clerk end the interaction on a positive and upbeat note?\"\n",
    "\"\"\"\n",
    "\n",
    "res = summarize_text(llm, prompt_prefix, \"./data/bank-call-center-transcript.txt\")\n",
    "display(JSON(json.loads(res)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize large documents\n",
    "To summarize larger documents, we can split the document into smaller chunks and summarize each chunk separately. We can then combine the summaries of each chunk to get the final summary.\n",
    "LangChain has a built-in chain for doing that. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in the document: 14386\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "llm=init_llm()\n",
    "\n",
    "large_pdf_path =\"./data/Large_language_model.pdf\"\n",
    "loader = PyPDFLoader(large_pdf_path)\n",
    "\n",
    "#output type is List[Document]\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "#count tokens in the document\n",
    "total_tokens = 0\n",
    "\n",
    "for page in pages:\n",
    "    total_tokens += llm.get_num_tokens(page.page_content)\n",
    "    \n",
    "# The document has more 14000 tokens. This is too many for the LLM to process in one go.\n",
    "# This is whay we split the document into smaller chunks.\n",
    "print(f\"Total tokens in the document: {total_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create summarization chain\n",
    "summary_chain = load_summarize_chain(llm=llm, chain_type='map_reduce',verbose=False )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There are following chain_types: stuff, map_reduce, refine, map-rerank\n",
    "See here for the details: https://docs.langchain.com/docs/components/chains/index_related_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Large language models (LLMs) are neural networks with billions of parameters, trained on large datasets of unlabeled text. They are used for a wide range of tasks, such as sentiment analysis, named-entity recognition, and part-of-speech tagging. LLMs are pre-trained on large datasets, and their performance is related to the size of the model, the size of the training dataset, the cost of training, and the performance after training. Instruction tuning and reinforcement learning from human feedback (RLHF) are used to fine-tune and train the LLM. Evaluation of LLMs is done by measuring their perplexity on a test set of unseen data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Many calls in loop causing RateLimitError: Too Many Requests\n",
    "#sum = summary_chain.run(pages)\n",
    "sum = summary_chain.run(pages[0:5])\n",
    "\n",
    "display(Markdown(sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
