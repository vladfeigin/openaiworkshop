{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://azuremlsdktestpypi.azureedge.net/embeddingstore/\n",
      "Collecting embeddingstore\n",
      "  Downloading https://azuremlsdktestpypi.blob.core.windows.net/repo/embeddingstore/embeddingstore-0.0.100488717-py3-none-any.whl?sv=2021-10-04&st=2023-07-24T03%3A30%3A19Z&se=2024-07-24T03%3A30%3A19Z&sr=b&sp=rl&sig=tFN%2FTuwEYnbACYTgyNiq8mHai6nzDQHu4h1aMkbfqwU%3D (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m225.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from embeddingstore) (5.9.5)\n",
      "Requirement already satisfied: faiss.cpu>=1.7.3 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from embeddingstore) (1.7.4)\n",
      "Requirement already satisfied: numpy>=1.24.1 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from embeddingstore) (1.25.1)\n",
      "Requirement already satisfied: pandas>=1.5.3 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from embeddingstore) (2.0.3)\n",
      "Requirement already satisfied: langchain>=0.0.123 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from embeddingstore) (0.0.187)\n",
      "Requirement already satisfied: openai>=0.27.0 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from embeddingstore) (0.27.6)\n",
      "Collecting flask>=2.2.3 (from embeddingstore)\n",
      "  Using cached Flask-2.3.2-py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied: requests>=2.28.1 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from embeddingstore) (2.31.0)\n",
      "Collecting Werkzeug>=2.3.3 (from flask>=2.2.3->embeddingstore)\n",
      "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting Jinja2>=3.1.2 (from flask>=2.2.3->embeddingstore)\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "Collecting itsdangerous>=2.1.2 (from flask>=2.2.3->embeddingstore)\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting click>=8.1.3 (from flask>=2.2.3->embeddingstore)\n",
      "  Downloading click-8.1.6-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting blinker>=1.6.2 (from flask>=2.2.3->embeddingstore)\n",
      "  Using cached blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from langchain>=0.0.123->embeddingstore) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from langchain>=0.0.123->embeddingstore) (2.0.18)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from langchain>=0.0.123->embeddingstore) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from langchain>=0.0.123->embeddingstore) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from langchain>=0.0.123->embeddingstore) (0.5.9)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from langchain>=0.0.123->embeddingstore) (2.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from langchain>=0.0.123->embeddingstore) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from langchain>=0.0.123->embeddingstore) (1.10.11)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from langchain>=0.0.123->embeddingstore) (8.2.2)\n",
      "Requirement already satisfied: tqdm in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from openai>=0.27.0->embeddingstore) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from pandas>=1.5.3->embeddingstore) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from pandas>=1.5.3->embeddingstore) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from pandas>=1.5.3->embeddingstore) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from requests>=2.28.1->embeddingstore) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from requests>=2.28.1->embeddingstore) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from requests>=2.28.1->embeddingstore) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from requests>=2.28.1->embeddingstore) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.123->embeddingstore) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.123->embeddingstore) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.123->embeddingstore) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.123->embeddingstore) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.123->embeddingstore) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.123->embeddingstore) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.123->embeddingstore) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.123->embeddingstore) (0.9.0)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2>=3.1.2->flask>=2.2.3->embeddingstore)\n",
      "  Using cached MarkupSafe-2.1.3-cp310-cp310-macosx_10_9_universal2.whl (17 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from pydantic<2,>=1->langchain>=0.0.123->embeddingstore) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.3->embeddingstore) (1.16.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.123->embeddingstore) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain>=0.0.123->embeddingstore) (1.0.0)\n",
      "Installing collected packages: MarkupSafe, itsdangerous, click, blinker, Werkzeug, Jinja2, flask, embeddingstore\n",
      "Successfully installed Jinja2-3.1.2 MarkupSafe-2.1.3 Werkzeug-2.3.6 blinker-1.6.2 click-8.1.6 embeddingstore-0.0.100488717 flask-2.3.2 itsdangerous-2.1.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install embeddingstore --extra-index-url https://azuremlsdktestpypi.azureedge.net/embeddingstore/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load Environment variables from .env file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import openai\n",
    "from embeddingstore.core.contracts import (\n",
    "    EmbeddingModelType,\n",
    "    StorageType,\n",
    "    StoreCoreConfig,\n",
    ")\n",
    "from embeddingstore.core.embeddingstore_core import EmbeddingStoreCore\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") \n",
    "OPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\n",
    "OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n",
    "OPENAI_MODEL_NAME = os.getenv(\"OPENAI_MODEL_NAME\")\n",
    "OPENAI_DEPLOYMENT_VERSION = os.getenv(\"OPENAI_DEPLOYMENT_VERSION\")\n",
    "\n",
    "OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "OPENAI_ADA_EMBEDDING_MODEL_NAME = os.getenv(\"OPENAI_ADA_EMBEDDING_MODEL_NAME\")\n",
    "\n",
    "OPENAI_DAVINCI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DAVINCI_DEPLOYMENT_NAME\")\n",
    "OPENAI_DAVINCI_MODEL_NAME = os.getenv(\"OPENAI_DAVINCI_MODEL_NAME\")\n",
    "\n",
    "# Configure OpenAI API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = OPENAI_DEPLOYMENT_VERSION\n",
    "openai.api_base = OPENAI_DEPLOYMENT_ENDPOINT\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_PREFIX = \"https://learn.microsoft.com/en-us/azure/machine-learning/\"\n",
    "URL_NAME_LIST = [\n",
    "    \"overview-what-is-azure-machine-learning\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Download the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/vladfeigin/myprojects/openai/workshops/dataai/openaiworkshop-new/openaiworkshop/Lab #3 - Create embeddings in pandas/data\n"
     ]
    }
   ],
   "source": [
    "local_file_path = os.path.join(os.getcwd(), \"data\")\n",
    "print(local_file_path)\n",
    "os.makedirs(local_file_path, exist_ok=True)\n",
    "for url_name in URL_NAME_LIST:\n",
    "    url = os.path.join(URL_PREFIX, url_name)\n",
    "    destination_path = os.path.join(local_file_path, url_name)\n",
    "    urllib.request.urlretrieve(url, destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create simple vector store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSION = 1536\n",
    "\n",
    "# Configure an embedding store to store index file.\n",
    "store_path = os.path.join(os.getcwd(), \"faiss_index_store\")\n",
    "config = StoreCoreConfig.create_config(\n",
    "    storage_type=StorageType.LOCAL,\n",
    "    store_identifier=store_path,\n",
    "    model_type=EmbeddingModelType.AOAI,\n",
    "    model_api_base=OPENAI_DEPLOYMENT_ENDPOINT,\n",
    "    model_api_key=OPENAI_API_KEY,\n",
    "    model_api_version=OPENAI_DEPLOYMENT_VERSION,\n",
    "    model_name=OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME,\n",
    "    dimension=DIMENSION,\n",
    "    create_if_not_exists=True,\n",
    ")\n",
    "store = EmbeddingStoreCore(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class EmbeddingStoreCore in module embeddingstore.core.embeddingstore_core:\n",
      "\n",
      "class EmbeddingStoreCore(builtins.object)\n",
      " |  EmbeddingStoreCore(config: embeddingstore.core.contracts.config.StoreCoreConfig)\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, config: embeddingstore.core.contracts.config.StoreCoreConfig)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  batch_insert_texts(self, texts: Iterable[str], metadatas: Optional[List[dict]] = None) -> None\n",
      " |  \n",
      " |  batch_insert_texts_with_embeddings(self, texts: Iterable[str], embeddings: Iterable[List[float]], metadatas: Optional[List[dict]] = None) -> None\n",
      " |  \n",
      " |  clear(self)\n",
      " |  \n",
      " |  save(self)\n",
      " |  \n",
      " |  search_by_embedding(self, query_embedding: List[float], top_k: int = 5) -> List[embeddingstore.core.contracts.entities.SearchResultEntity]\n",
      " |  \n",
      " |  search_by_text(self, query_text: str, top_k: int = 5) -> List[embeddingstore.core.contracts.entities.SearchResultEntity]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  create_store(store_identifier: str, dimension: int, storage_type: embeddingstore.core.contracts.types.StorageType = <StorageType.LOCAL: 'Local'>, local_cache_path: str = None, engine_type: embeddingstore.core.contracts.types.EngineType = <EngineType.LANGCHAIN: 'LangChain'>, index_type: embeddingstore.core.contracts.types.IndexType = <IndexType.FLATL2: 'FlatL2'>, model_type: embeddingstore.core.contracts.types.EmbeddingModelType = <EmbeddingModelType.NONE: 'None'>, model_name: str = None, model_api_base: str = None, model_api_version: str = None, auto_sync: bool = False, embedding_function: Any = None, secret_source_type: embeddingstore.core.contracts.types.SecretSourceType = <SecretSourceType.PLAIN: 'Plain'>, akv_url: str = None, credential: str = None, max_file_size: int = None, blob_conn_str: str = None, model_api_key: str = None, log_handlers: List[logging.Handler] = None, log_level: int = 51) from builtins.type\n",
      " |  \n",
      " |  get_store(store_identifier: Union[str, List[str]], dimension: int = None, storage_type: embeddingstore.core.contracts.types.StorageType = <StorageType.LOCAL: 'Local'>, local_cache_path=None, secret_source_type: embeddingstore.core.contracts.types.SecretSourceType = <SecretSourceType.PLAIN: 'Plain'>, akv_url=None, credential: str = None, max_file_size=None, blob_conn_str: str = None, model_api_key: str = None, log_handlers: List[logging.Handler] = None, log_level: int = 51) from builtins.type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(EmbeddingStoreCore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_chunks(file_name: str) -> List[str]:\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
    "        page_content = f.read()\n",
    "        # use BeautifulSoup to parse HTML content\n",
    "        soup = BeautifulSoup(page_content, \"html.parser\")\n",
    "        text = soup.get_text(\" \", strip=True)\n",
    "        chunks = []\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=30)\n",
    "        for chunk in splitter.split_text(text):\n",
    "            chunks.append(chunk)\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Chunk every file and save in a vector store**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIConnectionError",
     "evalue": "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/urllib3/connection.py:454\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    456\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.12_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.12_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.12_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:287\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line:\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# sending a valid response.\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[39mraise\u001b[39;00m RemoteDisconnected(\u001b[39m\"\u001b[39m\u001b[39mRemote end closed connection without\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39m response\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    289\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:844\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    842\u001b[0m     new_e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, new_e)\n\u001b[0;32m--> 844\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    845\u001b[0m     method, url, error\u001b[39m=\u001b[39;49mnew_e, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    846\u001b[0m )\n\u001b[1;32m    847\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/urllib3/util/retry.py:470\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_method_retryable(method):\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mraise\u001b[39;00m reraise(\u001b[39mtype\u001b[39;49m(error), error, _stacktrace)\n\u001b[1;32m    471\u001b[0m \u001b[39melif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/urllib3/util/util.py:38\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m     39\u001b[0m \u001b[39mraise\u001b[39;00m value\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/urllib3/connection.py:454\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    456\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.12_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.12_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.12_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/http/client.py:287\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line:\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# sending a valid response.\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[39mraise\u001b[39;00m RemoteDisconnected(\u001b[39m\"\u001b[39m\u001b[39mRemote end closed connection without\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39m response\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    289\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/openai/api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    597\u001b[0m         method,\n\u001b[1;32m    598\u001b[0m         abs_url,\n\u001b[1;32m    599\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    600\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    601\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    602\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    603\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    604\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/requests/adapters.py:501\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n\u001b[1;32m    503\u001b[0m \u001b[39mexcept\u001b[39;00m MaxRetryError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m     metadatas \u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m: file}] \u001b[39m*\u001b[39m count\n\u001b[1;32m     15\u001b[0m \u001b[39m# Embed chunks into embeddings, generate index in embedding store.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m# If your data is large, inserting too many chunks at once may cause\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m# rate limit error，you can refer to the following link to find solution\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m# https://learn.microsoft.com/en-us/azure/cognitive-services/openai/quotas-limits\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m store\u001b[39m.\u001b[39;49mbatch_insert_texts(chunks, metadatas)\n\u001b[1;32m     20\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCreate index for \u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m file successfully.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/embeddingstore/core/logging/utils.py:97\u001b[0m, in \u001b[0;36mLoggingUtils.log_event.<locals>.decorator_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m failed \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     98\u001b[0m     event_logger\u001b[39m.\u001b[39mtelemetry_event_completed(\n\u001b[1;32m     99\u001b[0m         event_name\u001b[39m=\u001b[39mevent_name\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    101\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/embeddingstore/core/embeddingstore_core.py:148\u001b[0m, in \u001b[0;36mEmbeddingStoreCore.batch_insert_texts\u001b[0;34m(self, texts, metadatas)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39m@LoggingUtils\u001b[39m\u001b[39m.\u001b[39mlog_event(\n\u001b[1;32m    142\u001b[0m     package_name\u001b[39m=\u001b[39m__package__,\n\u001b[1;32m    143\u001b[0m     event_name\u001b[39m=\u001b[39mStoreCoreEventNames\u001b[39m.\u001b[39mBATCH_INSERT_TEXTS,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    146\u001b[0m )\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbatch_insert_texts\u001b[39m(\u001b[39mself\u001b[39m, texts: Iterable[\u001b[39mstr\u001b[39m], metadatas: Optional[List[\u001b[39mdict\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__store\u001b[39m.\u001b[39;49mbatch_insert_texts(texts, metadatas)\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/embeddingstore/core/store/local_based_store.py:14\u001b[0m, in \u001b[0;36mLocalBasedStore.batch_insert_texts\u001b[0;34m(self, texts, metadatas)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbatch_insert_texts\u001b[39m(\u001b[39mself\u001b[39m, texts: Iterable[\u001b[39mstr\u001b[39m], metadatas: Optional[List[\u001b[39mdict\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mbatch_insert_texts(texts, metadatas)\n\u001b[1;32m     15\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__dump_data_and_index()\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/embeddingstore/core/store/in_memory_store.py:13\u001b[0m, in \u001b[0;36mInMemoryStore.batch_insert_texts\u001b[0;34m(self, texts, metadatas)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbatch_insert_texts\u001b[39m(\u001b[39mself\u001b[39m, texts: Iterable[\u001b[39mstr\u001b[39m], metadatas: Optional[List[\u001b[39mdict\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mbatch_insert_texts(texts, metadatas)\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/embeddingstore/core/engine/langchain_engine.py:38\u001b[0m, in \u001b[0;36mLangChainEngine.batch_insert_texts\u001b[0;34m(self, texts, metadatas)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbatch_insert_texts\u001b[39m(\u001b[39mself\u001b[39m, texts: Iterable[\u001b[39mstr\u001b[39m], metadatas: Optional[List[\u001b[39mdict\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__langchain_faiss\u001b[39m.\u001b[39;49madd_texts(texts, metadatas)\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/langchain/vectorstores/faiss.py:151\u001b[0m, in \u001b[0;36mFAISS.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    147\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf trying to add texts, the underlying docstore should support \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madding items, which \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocstore\u001b[39m}\u001b[39;00m\u001b[39m does not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m     )\n\u001b[1;32m    150\u001b[0m \u001b[39m# Embed and create the documents.\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m embeddings \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_function(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts]\n\u001b[1;32m    152\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__add(texts, embeddings, metadatas\u001b[39m=\u001b[39mmetadatas, ids\u001b[39m=\u001b[39mids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/langchain/vectorstores/faiss.py:151\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    147\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf trying to add texts, the underlying docstore should support \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madding items, which \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocstore\u001b[39m}\u001b[39;00m\u001b[39m does not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m     )\n\u001b[1;32m    150\u001b[0m \u001b[39m# Embed and create the documents.\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m embeddings \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_function(text) \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts]\n\u001b[1;32m    152\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__add(texts, embeddings, metadatas\u001b[39m=\u001b[39mmetadatas, ids\u001b[39m=\u001b[39mids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/embeddingstore/core/utils/retry_utils.py:19\u001b[0m, in \u001b[0;36mretry_and_handle_exceptions.<locals>.deco_retry.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_retries):\n\u001b[1;32m     18\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     20\u001b[0m     \u001b[39mexcept\u001b[39;00m exception_to_check \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     21\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m max_retries \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/embeddingstore/core/embeddings/aoai_embedding.py:26\u001b[0m, in \u001b[0;36mAOAIEmbedding.embed\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m@retry_and_handle_exceptions\u001b[39m(exception_to_check\u001b[39m=\u001b[39mopenai\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mRateLimitError,\n\u001b[1;32m     23\u001b[0m                              max_retries\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[1;32m     24\u001b[0m                              extract_delay_from_error_message\u001b[39m=\u001b[39mextract_delay_from_rate_limit_error_msg)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39membed\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[0;32m---> 26\u001b[0m     \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     27\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtext,\n\u001b[1;32m     28\u001b[0m         engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__config\u001b[39m.\u001b[39;49mmodel_name)[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/openai/api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[1;32m    291\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    292\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    293\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    294\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    295\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/myprojects/openai/workshops/dataai/openaiworkshop-new/.venv/lib/python3.10/site-packages/openai/api_requestor.py:609\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 609\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mAPIConnectionError(\n\u001b[1;32m    610\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError communicating with OpenAI: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)\n\u001b[1;32m    611\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    612\u001b[0m util\u001b[39m.\u001b[39mlog_debug(\n\u001b[1;32m    613\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOpenAI API response\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    614\u001b[0m     path\u001b[39m=\u001b[39mabs_url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    617\u001b[0m     request_id\u001b[39m=\u001b[39mresult\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mX-Request-Id\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    618\u001b[0m )\n\u001b[1;32m    619\u001b[0m \u001b[39m# Don't read the whole stream for debug logging unless necessary.\u001b[39;00m\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ],
   "source": [
    "for root, _, files in os.walk(local_file_path):\n",
    "    for file in files:\n",
    "        each_file_path = os.path.join(root, file)\n",
    "\n",
    "        # Split the file into chunks.\n",
    "        chunks = get_file_chunks(each_file_path)\n",
    "        count = len(chunks)\n",
    "        if URL_PREFIX is not None:\n",
    "            metadatas = [\n",
    "                {\"title\": file, \"source\": os.path.join(URL_PREFIX, file)}\n",
    "            ] * count\n",
    "        else:\n",
    "            metadatas = [{\"title\": file}] * count\n",
    "\n",
    "        # Embed chunks into embeddings, generate index in embedding store.\n",
    "        # If your data is large, inserting too many chunks at once may cause\n",
    "        # rate limit error，you can refer to the following link to find solution\n",
    "        # https://learn.microsoft.com/en-us/azure/cognitive-services/openai/quotas-limits\n",
    "        store.batch_insert_texts(chunks, metadatas)\n",
    "        print(f\"Create index for {file} file successfully.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = store.search_by_text(\"Azure Machine Learning\", top_k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
